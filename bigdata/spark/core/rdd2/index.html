<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.42">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <title>Spark Core | zmn.cn</title><meta name="description" content="后端开发知识库">
    <link rel="modulepreload" href="/doc/assets/app.40df414d.js"><link rel="modulepreload" href="/doc/assets/index.html.9b6544ca.js"><link rel="modulepreload" href="/doc/assets/index.html.cafd859a.js"><link rel="prefetch" href="/doc/assets/index.html.ac157e58.js"><link rel="prefetch" href="/doc/assets/index.html.795c9140.js"><link rel="prefetch" href="/doc/assets/index.html.fd51b8b2.js"><link rel="prefetch" href="/doc/assets/index.html.0c15a99b.js"><link rel="prefetch" href="/doc/assets/index.html.0c59ef61.js"><link rel="prefetch" href="/doc/assets/index.html.f10e9c63.js"><link rel="prefetch" href="/doc/assets/index.html.b5bfa26a.js"><link rel="prefetch" href="/doc/assets/index.html.e8912321.js"><link rel="prefetch" href="/doc/assets/index.html.e524e2c7.js"><link rel="prefetch" href="/doc/assets/index.html.e2c03529.js"><link rel="prefetch" href="/doc/assets/index.html.1a75e17e.js"><link rel="prefetch" href="/doc/assets/index.html.27d315d2.js"><link rel="prefetch" href="/doc/assets/index.html.8527be29.js"><link rel="prefetch" href="/doc/assets/index.html.5603dc63.js"><link rel="prefetch" href="/doc/assets/index.html.a735b5dd.js"><link rel="prefetch" href="/doc/assets/index.html.68217935.js"><link rel="prefetch" href="/doc/assets/index.html.79799519.js"><link rel="prefetch" href="/doc/assets/index.html.6881f0e6.js"><link rel="prefetch" href="/doc/assets/index.html.e7ff66c5.js"><link rel="prefetch" href="/doc/assets/index.html.b3989c09.js"><link rel="prefetch" href="/doc/assets/index.html.90a11c7e.js"><link rel="prefetch" href="/doc/assets/index.html.e552d764.js"><link rel="prefetch" href="/doc/assets/index.html.a2e921be.js"><link rel="prefetch" href="/doc/assets/index.html.40de4d57.js"><link rel="prefetch" href="/doc/assets/index.html.8dfb5661.js"><link rel="prefetch" href="/doc/assets/index.html.0b633e02.js"><link rel="prefetch" href="/doc/assets/index.html.325a81ac.js"><link rel="prefetch" href="/doc/assets/index.html.fc94b663.js"><link rel="prefetch" href="/doc/assets/index.html.a61a14dc.js"><link rel="prefetch" href="/doc/assets/index.html.915b115c.js"><link rel="prefetch" href="/doc/assets/index.html.74c3962d.js"><link rel="prefetch" href="/doc/assets/index.html.50e666c4.js"><link rel="prefetch" href="/doc/assets/index.html.bd0865d1.js"><link rel="prefetch" href="/doc/assets/index.html.670a8d54.js"><link rel="prefetch" href="/doc/assets/index.html.267a5925.js"><link rel="prefetch" href="/doc/assets/index.html.820a240a.js"><link rel="prefetch" href="/doc/assets/index.html.956e3861.js"><link rel="prefetch" href="/doc/assets/index.html.1eb9b84f.js"><link rel="prefetch" href="/doc/assets/index.html.085c7b3b.js"><link rel="prefetch" href="/doc/assets/index.html.cc6b0c3f.js"><link rel="prefetch" href="/doc/assets/index.html.878a89e3.js"><link rel="prefetch" href="/doc/assets/index.html.4349d3a7.js"><link rel="prefetch" href="/doc/assets/index.html.ad70fd8f.js"><link rel="prefetch" href="/doc/assets/index.html.ae8f6e96.js"><link rel="prefetch" href="/doc/assets/index.html.5904c85d.js"><link rel="prefetch" href="/doc/assets/index.html.67ad7772.js"><link rel="prefetch" href="/doc/assets/index.html.1fb78180.js"><link rel="prefetch" href="/doc/assets/index.html.79837727.js"><link rel="prefetch" href="/doc/assets/index.html.3b548d45.js"><link rel="prefetch" href="/doc/assets/index.html.3a65bcaf.js"><link rel="prefetch" href="/doc/assets/index.html.636ab4d4.js"><link rel="prefetch" href="/doc/assets/index.html.8c20145c.js"><link rel="prefetch" href="/doc/assets/index.html.93d3f714.js"><link rel="prefetch" href="/doc/assets/index.html.5cc28277.js"><link rel="prefetch" href="/doc/assets/index.html.587df9cf.js"><link rel="prefetch" href="/doc/assets/index.html.cffff73c.js"><link rel="prefetch" href="/doc/assets/index.html.0faea7db.js"><link rel="prefetch" href="/doc/assets/index.html.9ec36555.js"><link rel="prefetch" href="/doc/assets/index.html.4fbceb17.js"><link rel="prefetch" href="/doc/assets/index.html.a8892ad4.js"><link rel="prefetch" href="/doc/assets/index.html.1a7d6859.js"><link rel="prefetch" href="/doc/assets/index.html.5c08cce8.js"><link rel="prefetch" href="/doc/assets/index.html.ff1641e6.js"><link rel="prefetch" href="/doc/assets/index.html.10100559.js"><link rel="prefetch" href="/doc/assets/index.html.eca48ebd.js"><link rel="prefetch" href="/doc/assets/index.html.d9180794.js"><link rel="prefetch" href="/doc/assets/Spring.html.41ca96bd.js"><link rel="prefetch" href="/doc/assets/SpringBoot.html.c063ae1a.js"><link rel="prefetch" href="/doc/assets/SpringBoot源码.html.cdd45461.js"><link rel="prefetch" href="/doc/assets/SpringBoot高级.html.b3e5002b.js"><link rel="prefetch" href="/doc/assets/SpringMVC.html.25759dd3.js"><link rel="prefetch" href="/doc/assets/SpringSecurity.html.2ba8791d.js"><link rel="prefetch" href="/doc/assets/index.html.3afa53b5.js"><link rel="prefetch" href="/doc/assets/index.html.1963ae5c.js"><link rel="prefetch" href="/doc/assets/index.html.657aec84.js"><link rel="prefetch" href="/doc/assets/index.html.871b2105.js"><link rel="prefetch" href="/doc/assets/index.html.46266feb.js"><link rel="prefetch" href="/doc/assets/index.html.019ddb74.js"><link rel="prefetch" href="/doc/assets/index.html.2636a08e.js"><link rel="prefetch" href="/doc/assets/index.html.c6a50762.js"><link rel="prefetch" href="/doc/assets/index.html.6632d187.js"><link rel="prefetch" href="/doc/assets/index.html.480096df.js"><link rel="prefetch" href="/doc/assets/index.html.7bf9c484.js"><link rel="prefetch" href="/doc/assets/index.html.1ca63bf8.js"><link rel="prefetch" href="/doc/assets/index.html.ee1ff92b.js"><link rel="prefetch" href="/doc/assets/index.html.d1efbe95.js"><link rel="prefetch" href="/doc/assets/index.html.d302d742.js"><link rel="prefetch" href="/doc/assets/index.html.73b0a46e.js"><link rel="prefetch" href="/doc/assets/index.html.9b9e7b22.js"><link rel="prefetch" href="/doc/assets/index.html.5080b714.js"><link rel="prefetch" href="/doc/assets/index.html.e2de7b5a.js"><link rel="prefetch" href="/doc/assets/index.html.5a365a3f.js"><link rel="prefetch" href="/doc/assets/index.html.ea186b24.js"><link rel="prefetch" href="/doc/assets/index.html.da1b811a.js"><link rel="prefetch" href="/doc/assets/index.html.ba20a9fa.js"><link rel="prefetch" href="/doc/assets/index.html.23e205db.js"><link rel="prefetch" href="/doc/assets/index.html.92cefa25.js"><link rel="prefetch" href="/doc/assets/index.html.0519d6c0.js"><link rel="prefetch" href="/doc/assets/index.html.df3e94ce.js"><link rel="prefetch" href="/doc/assets/index.html.850ddff2.js"><link rel="prefetch" href="/doc/assets/index.html.060bc27e.js"><link rel="prefetch" href="/doc/assets/index.html.e9e53a65.js"><link rel="prefetch" href="/doc/assets/index.html.e03489a4.js"><link rel="prefetch" href="/doc/assets/index.html.5730a56d.js"><link rel="prefetch" href="/doc/assets/index.html.b2f4abe8.js"><link rel="prefetch" href="/doc/assets/index.html.c8328127.js"><link rel="prefetch" href="/doc/assets/index.html.887c0664.js"><link rel="prefetch" href="/doc/assets/index.html.4bf77624.js"><link rel="prefetch" href="/doc/assets/index.html.0e7972f9.js"><link rel="prefetch" href="/doc/assets/index.html.265aab2e.js"><link rel="prefetch" href="/doc/assets/index.html.ec74946d.js"><link rel="prefetch" href="/doc/assets/index.html.e3a2fec1.js"><link rel="prefetch" href="/doc/assets/index.html.36b699b6.js"><link rel="prefetch" href="/doc/assets/index.html.fdaf1cae.js"><link rel="prefetch" href="/doc/assets/index.html.ae3b119d.js"><link rel="prefetch" href="/doc/assets/index.html.b6c53f53.js"><link rel="prefetch" href="/doc/assets/index.html.0773f88d.js"><link rel="prefetch" href="/doc/assets/index.html.d571ef54.js"><link rel="prefetch" href="/doc/assets/index.html.86f9e908.js"><link rel="prefetch" href="/doc/assets/index.html.60f723ac.js"><link rel="prefetch" href="/doc/assets/index.html.01581c9b.js"><link rel="prefetch" href="/doc/assets/index.html.d96d738e.js"><link rel="prefetch" href="/doc/assets/index.html.5ddae78d.js"><link rel="prefetch" href="/doc/assets/index.html.7c0814ab.js"><link rel="prefetch" href="/doc/assets/index.html.965b7fff.js"><link rel="prefetch" href="/doc/assets/vue3快速上手.html.8773c5ea.js"><link rel="prefetch" href="/doc/assets/index.html.b2090b45.js"><link rel="prefetch" href="/doc/assets/index.html.f6fbe2a7.js"><link rel="prefetch" href="/doc/assets/index.html.5079d83e.js"><link rel="prefetch" href="/doc/assets/index.html.0e7d3814.js"><link rel="prefetch" href="/doc/assets/index.html.236535af.js"><link rel="prefetch" href="/doc/assets/index.html.e7057fa7.js"><link rel="prefetch" href="/doc/assets/index.html.0dfecf7e.js"><link rel="prefetch" href="/doc/assets/index.html.ba833381.js"><link rel="prefetch" href="/doc/assets/404.html.93146c89.js"><link rel="prefetch" href="/doc/assets/index.html.3b7265f0.js"><link rel="prefetch" href="/doc/assets/index.html.f94b83e6.js"><link rel="prefetch" href="/doc/assets/index.html.478d12bf.js"><link rel="prefetch" href="/doc/assets/index.html.9eee768a.js"><link rel="prefetch" href="/doc/assets/index.html.2b8b2ed7.js"><link rel="prefetch" href="/doc/assets/index.html.a370c4da.js"><link rel="prefetch" href="/doc/assets/index.html.4078504f.js"><link rel="prefetch" href="/doc/assets/index.html.0a470d26.js"><link rel="prefetch" href="/doc/assets/index.html.70589c68.js"><link rel="prefetch" href="/doc/assets/index.html.3e00e696.js"><link rel="prefetch" href="/doc/assets/index.html.a2857e37.js"><link rel="prefetch" href="/doc/assets/index.html.11a24d88.js"><link rel="prefetch" href="/doc/assets/index.html.13fcd6dc.js"><link rel="prefetch" href="/doc/assets/index.html.bb926e52.js"><link rel="prefetch" href="/doc/assets/index.html.83c356d4.js"><link rel="prefetch" href="/doc/assets/index.html.9093f441.js"><link rel="prefetch" href="/doc/assets/index.html.99329590.js"><link rel="prefetch" href="/doc/assets/index.html.a25f2824.js"><link rel="prefetch" href="/doc/assets/index.html.5dd4e8e8.js"><link rel="prefetch" href="/doc/assets/index.html.80a1a8a8.js"><link rel="prefetch" href="/doc/assets/index.html.e6aaf5e4.js"><link rel="prefetch" href="/doc/assets/index.html.4b4f53af.js"><link rel="prefetch" href="/doc/assets/index.html.63d82858.js"><link rel="prefetch" href="/doc/assets/index.html.02f66c42.js"><link rel="prefetch" href="/doc/assets/index.html.b02e0cb9.js"><link rel="prefetch" href="/doc/assets/index.html.b2cf2462.js"><link rel="prefetch" href="/doc/assets/index.html.4d88523a.js"><link rel="prefetch" href="/doc/assets/index.html.b6d3a8c2.js"><link rel="prefetch" href="/doc/assets/index.html.8e3bc1fc.js"><link rel="prefetch" href="/doc/assets/index.html.593a1904.js"><link rel="prefetch" href="/doc/assets/index.html.d0fdf009.js"><link rel="prefetch" href="/doc/assets/index.html.bb125db3.js"><link rel="prefetch" href="/doc/assets/index.html.7a967c9a.js"><link rel="prefetch" href="/doc/assets/index.html.ca6b22e1.js"><link rel="prefetch" href="/doc/assets/index.html.e1c469a1.js"><link rel="prefetch" href="/doc/assets/index.html.ff09b3af.js"><link rel="prefetch" href="/doc/assets/index.html.ec4bbb87.js"><link rel="prefetch" href="/doc/assets/index.html.12c1e355.js"><link rel="prefetch" href="/doc/assets/index.html.8a4045e6.js"><link rel="prefetch" href="/doc/assets/index.html.b54dc8a6.js"><link rel="prefetch" href="/doc/assets/index.html.721d96fd.js"><link rel="prefetch" href="/doc/assets/index.html.d855e8ed.js"><link rel="prefetch" href="/doc/assets/index.html.17fbd68b.js"><link rel="prefetch" href="/doc/assets/index.html.ad5ccf5a.js"><link rel="prefetch" href="/doc/assets/index.html.130dead3.js"><link rel="prefetch" href="/doc/assets/index.html.0bcc78cc.js"><link rel="prefetch" href="/doc/assets/index.html.557897f7.js"><link rel="prefetch" href="/doc/assets/index.html.1d57cd02.js"><link rel="prefetch" href="/doc/assets/index.html.df77ede5.js"><link rel="prefetch" href="/doc/assets/index.html.ac04a9ed.js"><link rel="prefetch" href="/doc/assets/index.html.037f3861.js"><link rel="prefetch" href="/doc/assets/index.html.08a635f2.js"><link rel="prefetch" href="/doc/assets/index.html.d37ad707.js"><link rel="prefetch" href="/doc/assets/index.html.af40cb25.js"><link rel="prefetch" href="/doc/assets/index.html.7b09b414.js"><link rel="prefetch" href="/doc/assets/index.html.ca416dcc.js"><link rel="prefetch" href="/doc/assets/index.html.f5eae5e4.js"><link rel="prefetch" href="/doc/assets/index.html.acf5622e.js"><link rel="prefetch" href="/doc/assets/index.html.77c30969.js"><link rel="prefetch" href="/doc/assets/index.html.ff8fef88.js"><link rel="prefetch" href="/doc/assets/index.html.b03ad9ee.js"><link rel="prefetch" href="/doc/assets/index.html.883bb815.js"><link rel="prefetch" href="/doc/assets/index.html.e5048f53.js"><link rel="prefetch" href="/doc/assets/index.html.80bf8279.js"><link rel="prefetch" href="/doc/assets/index.html.411d2f13.js"><link rel="prefetch" href="/doc/assets/index.html.e55b3889.js"><link rel="prefetch" href="/doc/assets/Spring.html.2f3df8d9.js"><link rel="prefetch" href="/doc/assets/SpringBoot.html.9cb899e2.js"><link rel="prefetch" href="/doc/assets/SpringBoot源码.html.6dd51782.js"><link rel="prefetch" href="/doc/assets/SpringBoot高级.html.74275d08.js"><link rel="prefetch" href="/doc/assets/SpringMVC.html.cf650f7b.js"><link rel="prefetch" href="/doc/assets/SpringSecurity.html.1e2f9882.js"><link rel="prefetch" href="/doc/assets/index.html.8489e95c.js"><link rel="prefetch" href="/doc/assets/index.html.4fc255fb.js"><link rel="prefetch" href="/doc/assets/index.html.6e298d1f.js"><link rel="prefetch" href="/doc/assets/index.html.dfb5c354.js"><link rel="prefetch" href="/doc/assets/index.html.55c13f7d.js"><link rel="prefetch" href="/doc/assets/index.html.9746da44.js"><link rel="prefetch" href="/doc/assets/index.html.5cad0d30.js"><link rel="prefetch" href="/doc/assets/index.html.a5a742fd.js"><link rel="prefetch" href="/doc/assets/index.html.2d7d46f5.js"><link rel="prefetch" href="/doc/assets/index.html.4fd15fc0.js"><link rel="prefetch" href="/doc/assets/index.html.5cf91540.js"><link rel="prefetch" href="/doc/assets/index.html.3d50e978.js"><link rel="prefetch" href="/doc/assets/index.html.21ff9d3b.js"><link rel="prefetch" href="/doc/assets/index.html.47b83ec4.js"><link rel="prefetch" href="/doc/assets/index.html.bc304f81.js"><link rel="prefetch" href="/doc/assets/index.html.b2a59940.js"><link rel="prefetch" href="/doc/assets/index.html.13415a43.js"><link rel="prefetch" href="/doc/assets/index.html.100ec837.js"><link rel="prefetch" href="/doc/assets/index.html.3472a443.js"><link rel="prefetch" href="/doc/assets/index.html.33aece6b.js"><link rel="prefetch" href="/doc/assets/index.html.e61dd289.js"><link rel="prefetch" href="/doc/assets/index.html.64183ae2.js"><link rel="prefetch" href="/doc/assets/index.html.446a1818.js"><link rel="prefetch" href="/doc/assets/index.html.97ea4a5c.js"><link rel="prefetch" href="/doc/assets/index.html.a6ef03fb.js"><link rel="prefetch" href="/doc/assets/index.html.3920cc47.js"><link rel="prefetch" href="/doc/assets/index.html.34f4e287.js"><link rel="prefetch" href="/doc/assets/index.html.1351290b.js"><link rel="prefetch" href="/doc/assets/index.html.84a20a4f.js"><link rel="prefetch" href="/doc/assets/index.html.e55a3317.js"><link rel="prefetch" href="/doc/assets/index.html.a5eeaab0.js"><link rel="prefetch" href="/doc/assets/index.html.a8d854c3.js"><link rel="prefetch" href="/doc/assets/index.html.74d28158.js"><link rel="prefetch" href="/doc/assets/index.html.ea3deaa2.js"><link rel="prefetch" href="/doc/assets/index.html.f5114c18.js"><link rel="prefetch" href="/doc/assets/index.html.ca8dada1.js"><link rel="prefetch" href="/doc/assets/index.html.0d3a5370.js"><link rel="prefetch" href="/doc/assets/index.html.13e899ea.js"><link rel="prefetch" href="/doc/assets/index.html.4f4461aa.js"><link rel="prefetch" href="/doc/assets/index.html.b6ced39d.js"><link rel="prefetch" href="/doc/assets/index.html.6c0283f0.js"><link rel="prefetch" href="/doc/assets/index.html.01661ebc.js"><link rel="prefetch" href="/doc/assets/index.html.657c6ed2.js"><link rel="prefetch" href="/doc/assets/index.html.f5f7aed0.js"><link rel="prefetch" href="/doc/assets/index.html.cdd6e499.js"><link rel="prefetch" href="/doc/assets/index.html.2d661523.js"><link rel="prefetch" href="/doc/assets/index.html.6893b4fb.js"><link rel="prefetch" href="/doc/assets/index.html.566e406c.js"><link rel="prefetch" href="/doc/assets/index.html.1357e2d3.js"><link rel="prefetch" href="/doc/assets/index.html.d910030e.js"><link rel="prefetch" href="/doc/assets/index.html.4d5146a8.js"><link rel="prefetch" href="/doc/assets/index.html.d830c4f5.js"><link rel="prefetch" href="/doc/assets/index.html.b1bef10b.js"><link rel="prefetch" href="/doc/assets/vue3快速上手.html.d36d3c30.js"><link rel="prefetch" href="/doc/assets/index.html.1e6ab806.js"><link rel="prefetch" href="/doc/assets/index.html.4125d933.js"><link rel="prefetch" href="/doc/assets/index.html.c5dc4567.js"><link rel="prefetch" href="/doc/assets/index.html.451edb2d.js"><link rel="prefetch" href="/doc/assets/index.html.a665dde3.js"><link rel="prefetch" href="/doc/assets/index.html.5ba5e8a1.js"><link rel="prefetch" href="/doc/assets/index.html.23b6b000.js"><link rel="prefetch" href="/doc/assets/index.html.629d6531.js"><link rel="prefetch" href="/doc/assets/404.html.d315880d.js"><link rel="prefetch" href="/doc/assets/404.bebaa092.js"><link rel="prefetch" href="/doc/assets/Layout.4134e473.js">
    <link rel="stylesheet" href="/doc/assets/style.83db67df.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/doc/" class=""><img class="logo" src="https://cdn-statics.zmn.cn/_nuxt/img/logo_web.b793f2a.png" alt="zmn.cn"><span class="site-name can-hide">zmn.cn</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><a href="/doc/" class="" aria-label="首页"><!--[--><!--]--> 首页 <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Java"><span class="title">Java</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Java"><span class="title">Java</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/doc/java/kafka/" class="" aria-label="Kafka"><!--[--><!--]--> Kafka <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/redis/" class="" aria-label="Redis"><!--[--><!--]--> Redis <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/skywalking/" class="" aria-label="SkyWalking"><!--[--><!--]--> SkyWalking <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/es/01/" class="" aria-label="ElasticSearch"><!--[--><!--]--> ElasticSearch <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/drools/" class="" aria-label="Drools"><!--[--><!--]--> Drools <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/jvm/01/" class="" aria-label="JVM"><!--[--><!--]--> JVM <!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="BigData"><span class="title">BigData</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="BigData"><span class="title">BigData</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/doc/bigdata/hadoop/core/hadoop/01/" class="" aria-label="Hadoop"><!--[--><!--]--> Hadoop <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/bigdata/scala/01base/" class="" aria-label="Scala"><!--[--><!--]--> Scala <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/bigdata/spark/core/base/" class="" aria-label="Spark"><!--[--><!--]--> Spark <!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><a class="external-link" href="https://github.com/faustine8/doc" rel="noopener noreferrer" target="_blank" aria-label="GitHub"><!--[--><!--]--> GitHub <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button class="toggle-dark-button" title="toggle dark mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><a href="/doc/" class="" aria-label="首页"><!--[--><!--]--> 首页 <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Java"><span class="title">Java</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Java"><span class="title">Java</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/doc/java/kafka/" class="" aria-label="Kafka"><!--[--><!--]--> Kafka <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/redis/" class="" aria-label="Redis"><!--[--><!--]--> Redis <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/skywalking/" class="" aria-label="SkyWalking"><!--[--><!--]--> SkyWalking <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/es/01/" class="" aria-label="ElasticSearch"><!--[--><!--]--> ElasticSearch <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/drools/" class="" aria-label="Drools"><!--[--><!--]--> Drools <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/jvm/01/" class="" aria-label="JVM"><!--[--><!--]--> JVM <!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="BigData"><span class="title">BigData</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="BigData"><span class="title">BigData</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/doc/bigdata/hadoop/core/hadoop/01/" class="" aria-label="Hadoop"><!--[--><!--]--> Hadoop <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/bigdata/scala/01base/" class="" aria-label="Scala"><!--[--><!--]--> Scala <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/bigdata/spark/core/base/" class="" aria-label="Spark"><!--[--><!--]--> Spark <!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><a class="external-link" href="https://github.com/faustine8/doc" rel="noopener noreferrer" target="_blank" aria-label="GitHub"><!--[--><!--]--> GitHub <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading">Spark Core <!----></p><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#第4节-rdd编程高阶" class="router-link-active router-link-exact-active sidebar-item" aria-label="第4节 RDD编程高阶"><!--[--><!--]--> 第4节 RDD编程高阶 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-1-序列化" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.1 序列化"><!--[--><!--]--> 4.1 序列化 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-2-rdd依赖关系" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.2 RDD依赖关系"><!--[--><!--]--> 4.2 RDD依赖关系 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-3-rdd持久化-缓存" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.3 RDD持久化/缓存"><!--[--><!--]--> 4.3 RDD持久化/缓存 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-4-rdd容错机制checkpoint" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.4 RDD容错机制Checkpoint"><!--[--><!--]--> 4.4 RDD容错机制Checkpoint <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-5-rdd的分区" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.5 RDD的分区"><!--[--><!--]--> 4.5 RDD的分区 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-6-rdd分区器" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.6 RDD分区器"><!--[--><!--]--> 4.6 RDD分区器 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-7-广播变量" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.7 广播变量"><!--[--><!--]--> 4.7 广播变量 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-8-累加器" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.8 累加器"><!--[--><!--]--> 4.8 累加器 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_4-9-topn的优化" class="router-link-active router-link-exact-active sidebar-item" aria-label="4.9 TopN的优化"><!--[--><!--]--> 4.9 TopN的优化 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#第5节-spark原理初探" class="router-link-active router-link-exact-active sidebar-item" aria-label="第5节 Spark原理初探"><!--[--><!--]--> 第5节 Spark原理初探 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_5-1-standalone模式作业提交" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.1 Standalone模式作业提交"><!--[--><!--]--> 5.1 Standalone模式作业提交 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_5-2-shuffle原理" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2 Shuffle原理"><!--[--><!--]--> 5.2 Shuffle原理 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/spark/core/rdd2/#_5-3-rdd编程优化" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.3 RDD编程优化"><!--[--><!--]--> 5.3 RDD编程优化 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><!--]--></ul><!--]--></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><h1 id="spark-core" tabindex="-1"><a class="header-anchor" href="#spark-core" aria-hidden="true">#</a> Spark Core</h1><h2 id="第4节-rdd编程高阶" tabindex="-1"><a class="header-anchor" href="#第4节-rdd编程高阶" aria-hidden="true">#</a> 第4节 RDD编程高阶</h2><blockquote><p><a href="https://blog.csdn.net/chengh1993/article/details/114239397" target="_blank" rel="noopener noreferrer">https://blog.csdn.net/chengh1993/article/details/114239397<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><h3 id="_4-1-序列化" tabindex="-1"><a class="header-anchor" href="#_4-1-序列化" aria-hidden="true">#</a> 4.1 序列化</h3><p>在实际开发中会自定义一些对RDD的操作，此时需要注意的是:</p><p>初始化工作是在Driver端进行的，实际运行程序是在Executor端进行的，这就涉及到了进程通信，是需要序列化的。</p><blockquote><p>可以简单的认为 <code>SparkContext</code> 代表Driver。</p></blockquote><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">class</span> MyClass1<span class="token punctuation">(</span>x<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token keyword">val</span> num<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> x
<span class="token punctuation">}</span>

<span class="token keyword">case</span> <span class="token keyword">class</span> MyClass2<span class="token punctuation">(</span>num<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> MyClass3<span class="token punctuation">(</span>x<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Serializable <span class="token punctuation">{</span>
  <span class="token keyword">val</span> num<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> x
<span class="token punctuation">}</span>

<span class="token keyword">object</span> SerializableDemo <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">// 初始化</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getCanonicalName<span class="token punctuation">.</span>init<span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;WARN&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> o1 <span class="token operator">=</span> <span class="token keyword">new</span> MyClass1<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span>
    <span class="token comment">// println(s&quot;o1.num = ${o1.num}&quot;)</span>

    <span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">20</span><span class="token punctuation">)</span>
    <span class="token comment">// 方法</span>
    <span class="token keyword">def</span> add1<span class="token punctuation">(</span>x<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token number">100</span>
    <span class="token comment">// 函数</span>
    <span class="token keyword">val</span> add2 <span class="token operator">=</span> add1 _

    <span class="token comment">// 函数、方法都具备序列化和反序列化的能力</span>
    <span class="token comment">// rdd1.map(add1(_)).foreach(println)</span>
    <span class="token comment">// println(&quot;-----------------------&quot;)</span>
    <span class="token comment">// rdd1.map(add2(_)).foreach(println)</span>

    <span class="token keyword">val</span> object1 <span class="token operator">=</span> <span class="token keyword">new</span> MyClass1<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
    <span class="token comment">// 下面的不能序列化, 因为object1是自定义class</span>
    <span class="token comment">// rdd1.map(x =&gt; object1.num + x).foreach(println) // Task not serializable</span>

    <span class="token comment">// 解决方案一：使用case class, scala 提供了序列化和反序列化方法</span>
    <span class="token keyword">val</span> object2 <span class="token operator">=</span> MyClass2<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
    rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> object2<span class="token punctuation">.</span>num <span class="token operator">+</span> x<span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">&quot;--------------------------&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">// 解决方案二：MyClass3 实现 Serializable 接口</span>
    <span class="token keyword">val</span> object3 <span class="token operator">=</span> <span class="token keyword">new</span> MyClass3<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
    rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> object3<span class="token punctuation">.</span>num <span class="token operator">+</span> x<span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">&quot;--------------------------&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">// 解决方案三: 延迟创建</span>
    <span class="token keyword">lazy</span> <span class="token keyword">val</span> object4 <span class="token operator">=</span> <span class="token keyword">new</span> MyClass1<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>
    rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> object4<span class="token punctuation">.</span>num <span class="token operator">+</span> x<span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br></div></div><p>备注:</p><ul><li>如果在方法、函数的定义中引用了不可序列化的对象，也会导致任务不能序列化</li><li>延迟创建的解决方案较为简单，适用性广</li></ul><h3 id="_4-2-rdd依赖关系" tabindex="-1"><a class="header-anchor" href="#_4-2-rdd依赖关系" aria-hidden="true">#</a> 4.2 RDD依赖关系</h3><p>RDD只支持粗粒度转换，即在大量记录上执行的单个操作。将创建RDD的一系列Lineage(血统)记录下来， 以便恢复丢失的分区。</p><p>RDD的Lineage会记录RDD的元数据信息和转换行为，当该RDD的部分分区数据丢失时， 可根据这些信息来重新运算和恢复丢失的数据分区。</p><p><img src="/doc/assets/README-1648709608586.e2319e54.png" alt="RDD依赖"></p><p>RDD和它依赖的父RDD(s)的关系有两种不同的类型，即窄依赖(narrow dependency)和宽依赖(wide dependency)。</p><p>依赖有2个作用: 一是用来解决数据容错;二是用来划分stage。</p><ul><li>窄依赖: 1:1 或 n:1</li><li>宽依赖: n:m; <em>意味着有shuffle</em></li></ul><blockquote><p>要能够准确、迅速的区分哪些算子是宽依赖; (记住宽依赖，其他都是窄依赖)</p></blockquote><blockquote><p>速记心得：宽依赖的算子都很有特点，主要有两类：<code>join</code> 系列, 和 <code>xxByKey</code> 系列</p></blockquote><p><img src="/doc/assets/README-1648709704859.d6f98d36.png" alt="窄依赖和宽依赖"></p><p><img src="/doc/assets/README-1648709732726.9ab4f29b.png" alt="依赖关系"></p><blockquote><p>宽依赖只有 <code>ShuffleDependency</code> 一种实现，而窄依赖有多种实现。</p></blockquote><hr><p>DAG(Directed Acyclic Graph) 有向无环图。</p><p>原始的RDD通过一系列的转换就就形成了DAG，根据RDD之间的依赖关系的不同，将DAG划分成不同的Stage:</p><ul><li>对于窄依赖，partition 的转换处理在Stage中完成计算</li><li>对于宽依赖，由于有Shuffle的存在，只能在 parent RDD处理完成后，才能开始接下来的计算</li><li>宽依赖是划分Stage的依据</li></ul><p><img src="/doc/assets/README-1648709836341.46e7b44e.png" alt="DAG示意图"></p><p>RDD任务切分中间分为: Driver program、Job、Stage(TaskSet)和Task</p><ul><li>Driver program: 初始化一个SparkContext即生成一个Spark应用</li><li>Job: 一个Action算子就会生成一个Job</li><li>Stage: 根据RDD之间的依赖关系的不同将Job划分成不同的Stage，遇到一个宽依赖则划分一个Stage</li><li>Task: Stage是一个TaskSet，将Stage划分的结果发送到不同的 Executor 执行即为一个Task</li></ul><p>Task是Spark中任务调度的最小单位; 每个Stage包含许多Task，这些Task执行的计算逻辑相同的， 计算的数据不同。</p><blockquote><p>注意: <code>Driver program</code> -&gt; <code>Job</code> -&gt; <code>Stage</code> -&gt; <code>Task</code> 每一层都是1对n的关系。</p></blockquote><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// 窄依赖</span>
<span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">11</span> to <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>union<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>
rdd3<span class="token punctuation">.</span>dependencies<span class="token punctuation">.</span>size
<span class="token comment">// res0: Int = 2</span>
 
rdd3<span class="token punctuation">.</span>dependencies
<span class="token comment">// res1: Seq[org.apache.spark.Dependency[_]] = ArrayBuffer(org.apache.spark.RangeDependency@52a3a9ef, org.apache.spark.RangeDependency@25d77b18)</span>
<span class="token comment">// 两个窄依赖</span>
 
<span class="token comment">// 打印rdd1的数据</span>
rdd3<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>collect
<span class="token comment">// res2: Array[_] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)                           </span>
 
<span class="token comment">// 打印rdd2的数据</span>
rdd3<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>collect
<span class="token comment">//res3: Array[_] = Array(11, 12, 13, 14, 15, 16, 17, 18, 19, 20)</span>
 
<span class="token comment">// 宽依赖</span>
<span class="token keyword">val</span> random <span class="token operator">=</span> <span class="token keyword">new</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random
<span class="token keyword">val</span> arr <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>idx <span class="token keyword">=&gt;</span> random<span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
<span class="token comment">// rdd2: org.apache.spark.rdd.RDD[(Int, Int)] = ShuffledRDD[5] at reduceByKey at &lt;console&gt;:25</span>
 
<span class="token comment">// 观察依赖</span>
rdd2<span class="token punctuation">.</span>dependencies
<span class="token comment">//res4: Seq[org.apache.spark.Dependency[_]] = List(org.apache.spark.ShuffleDependency@4c14904e)</span>
 
rdd2<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>collect
<span class="token comment">// res5: Array[_] = Array((76,1), (54,1), (92,1), (...</span>
 
rdd2<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>collect
<span class="token comment">// res6: Array[_] = Array(76, 54, 92, 55, 8, 74, 86, ...</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br></div></div><h4 id="再谈wordcount" tabindex="-1"><a class="header-anchor" href="#再谈wordcount" aria-hidden="true">#</a> 再谈WordCount</h4><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/wcinput/wc.txt&quot;</span><span class="token punctuation">)</span>
<span class="token comment">// rdd1: org.apache.spark.rdd.RDD[String] = /wcinput/wc.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:24</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\\s+&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">// rdd2: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at flatMap at &lt;console&gt;:25</span>
<span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">// rdd3: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[3] at map at &lt;console&gt;:25</span>
<span class="token keyword">val</span> rdd4 <span class="token operator">=</span> rdd3<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
<span class="token comment">// rdd4: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:25</span>
<span class="token keyword">val</span> rdd5 <span class="token operator">=</span> rdd4<span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">// rdd5: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[7] at sortByKey at &lt;console&gt;:25</span>
rdd5<span class="token punctuation">.</span>count
<span class="token comment">// res0: Long = 6</span>


<span class="token comment">// 查看RDD的血缘关系</span>
rdd1<span class="token punctuation">.</span>toDebugString
<span class="token comment">// res1: String =</span>
<span class="token comment">// (2) /wcinput/wc.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:24 []</span>
<span class="token comment">//  |  /wcinput/wc.txt HadoopRDD[0] at textFile at &lt;console&gt;:24 []</span>
 
rdd5<span class="token punctuation">.</span>toDebugString
<span class="token comment">// res2: String =</span>
<span class="token comment">// (2) ShuffledRDD[7] at sortByKey at &lt;console&gt;:25 []</span>
<span class="token comment">// +-(2) ShuffledRDD[4] at reduceByKey at &lt;console&gt;:25 []</span>
<span class="token comment">//    +-(2) MapPartitionsRDD[3] at map at &lt;console&gt;:25 []</span>
<span class="token comment">//       |  MapPartitionsRDD[2] at flatMap at &lt;console&gt;:25 []</span>
<span class="token comment">//       |  /wcinput/wc.txt MapPartitionsRDD[1] at textFile at &lt;console&gt;:24 []</span>
<span class="token comment">//       |  /wcinput/wc.txt HadoopRDD[0] at textFile at &lt;console&gt;:24 []</span>


<span class="token comment">// 查看依赖</span>
rdd1<span class="token punctuation">.</span>dependencies
<span class="token comment">// res3: Seq[org.apache.spark.Dependency[_]] = List(org.apache.spark.OneToOneDependency@55ec9270)</span>
rdd1<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd
<span class="token comment">// res4: org.apache.spark.rdd.RDD[_] = /wcinput/wc.txt HadoopRDD[0] at textFile at &lt;console&gt;:24</span>
 
rdd5<span class="token punctuation">.</span>dependencies
<span class="token comment">// res5: Seq[org.apache.spark.Dependency[_]] = List(org.apache.spark.ShuffleDependency@6c9de8a9)</span>
rdd5<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd
<span class="token comment">// res6: org.apache.spark.rdd.RDD[_] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:25</span>
 
<span class="token comment">// 查看最佳计算的优先位置</span>
<span class="token keyword">val</span> hadoopRDD <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd
<span class="token comment">// hadoopRDD: org.apache.spark.rdd.RDD[_] = /wcinput/wc.txt HadoopRDD[0] at textFile at &lt;console&gt;:24</span>
hadoopRDD<span class="token punctuation">.</span>preferredLocations<span class="token punctuation">(</span>hadoopRDD<span class="token punctuation">.</span>partitions<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">// res7: Seq[String] = ArraySeq(linux123, linux121, linux122)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br></div></div><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 使用 hdfs 命令检查文件情况</span>
hdfs <span class="token function">fsck</span> /wcinput/wc.txt -files -blocks -locations
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>问题：上面的 <code>WordCount</code> 中一共几个 <code>job</code>，几个 <code>Stage</code>，几个 <code>Task</code>？</p><p><img src="/doc/assets/README-1648710036263.bb927647.png" alt="WordCount执行流程"></p><p>本例中整个过程分为1个job，3个Stage；6个Task。</p><p><img src="/doc/assets/README-1648775963878.cd598c5d.png" alt="WorkCount执行详情"></p><blockquote><p>为什么这里显示有2个job? 参见RDD分区器。</p></blockquote><h3 id="_4-3-rdd持久化-缓存" tabindex="-1"><a class="header-anchor" href="#_4-3-rdd持久化-缓存" aria-hidden="true">#</a> 4.3 RDD持久化/缓存</h3><p><em>涉及到的算子: <code>persist</code>、<code>cache</code>、<code>unpersist</code>; 都是 Transformation</em></p><p>缓存是将计算结果写入不同的介质，用户定义可定义存储级别(存储级别定义了缓存存储的介质， 目前支持内存、堆外内存、磁盘);</p><p>通过缓存，Spark避免了RDD上的重复计算，能够极大地提升计算速度;</p><p>RDD持久化或缓存，是Spark最重要的特征之一。可以说，缓存是Spark构建迭代式算法和快速交互式查询的关键因素;</p><p>Spark速度非常快的原因之一，就是在内存中持久化(或缓存)一个数据集。当持久化一个RDD后， 每一个节点都将把计算的分片结果保存在内存中，并在对此数据集(或者衍生出的数据集)进行的其他动作(Action)中重用。 这使得后续的动作变得更加迅速;</p><p>使用 <code>persist()</code> 方法对一个RDD标记为持久化。之所以说“标记为持久化”，是因为出现 <code>persist()</code> 语句的地方， 并不会马上计算生成RDD并把它持久化，而是要等到遇到第一个行动操作触发真正计算以后，才会把计算结果进行持久化;</p><p><img src="/doc/assets/README-1648710273076.c4e85c57.png" alt="RDD持久化"></p><p>通过 <code>persist()</code> 或 <code>cache()</code> 方法可以标记一个要被持久化的RDD，持久化被触发， RDD 将会被保留在计算节点的内存中并重用;</p><p>什么时候缓存数据，需要对空间和速度进行权衡。一般情况下，如果多个动作需要用到某个 RDD， 而它的计算代价又很高，那么就应该把这个 RDD 缓存起来;</p><p><em>缓存有可能丢失，或者存储于内存的数据由于内存不足而被删除。</em> RDD的缓存的容错机制保证了 即使缓存丢失也能保证计算的正确执行。通过基于RDD的一系列的转换，丢失的数据会被重算。 RDD的各个Partition是相对独立的，因此只需要计算丢失的部分即可，并不需要重算全部Partition。</p><hr><p><code>persist()</code> 的参数可以指定持久化级别参数;</p><p>使用 <code>cache()</code> 方法时，会调用 <code>persist(MEMORY_ONLY)</code>，即:</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code>cache<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>Memeory_ONLY<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><blockquote><p>也就是说 <code>cache()</code> 不过是 <code>persist()</code> 的简写。</p></blockquote><p>使用 <code>unpersist()</code> 方法手动地把持久化的RDD从缓存中移除;</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">/**
 * Persist this RDD with the default storage level (`MEMORY_ONLY`).
 */</span>
<span class="token keyword">def</span> cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> JavaDoubleRDD <span class="token operator">=</span> fromRDD<span class="token punctuation">(</span>srdd<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">/**
 * Set this RDD&#39;s storage level to persist its values across operations after the first time
 * it is computed. Can only be called once on each RDD.
 */</span>
<span class="token keyword">def</span> persist<span class="token punctuation">(</span>newLevel<span class="token operator">:</span> StorageLevel<span class="token punctuation">)</span><span class="token operator">:</span> JavaDoubleRDD <span class="token operator">=</span> fromRDD<span class="token punctuation">(</span>srdd<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>newLevel<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p><img src="/doc/assets/README-1648710673741.1b16060c.png" alt="缓存级别1"></p><p><img src="/doc/assets/README-1648710695895.7a59a541.png" alt="缓存级别2"></p><table><thead><tr><th>存储级别</th><th>描述</th></tr></thead><tbody><tr><td>MEMORY_ONLY</td><td>将RDD 作为反序列化的对象存储JVM 中。如果 RDD不能被内存装下，一些分区将不会被缓存， 并且在需要的时候被重新计算。 默认的缓存级别</td></tr><tr><td>MEMORY_AND_DISK</td><td>将RDD 作为反序列化的的对象存储在JVM 中。如 果RDD不能被与内存装下，超出的分区将被保存 在硬盘上，并且在需要时被读取</td></tr><tr><td>MEMORY_ONLY_SER</td><td>将RDD 作为序列化的的对象进行存储(每一分区 一个字节数组)。 通常来说，这比将对象反序列 化的空间利用率更高，读取时会比较占用CPU</td></tr><tr><td>MEMORY_AND_DISK_SER</td><td>与MEMORY_ONLY_SER 相似，但是把超出内存的 分区将存储在硬盘上而不是在每次需要的时候重 新计算</td></tr><tr><td>DISK_ONLY</td><td>只将RDD 分区存储在硬盘上</td></tr><tr><td>DISK_ONLY_2等带2的</td><td>与上述的存储级别一样，但是将每一个分区都复制到集群的两个结点上</td></tr></tbody></table><blockquote><p><code>cache RDD</code> 以分区为单位; 程序执行完毕后，系统会清理 <code>cache</code> 数据;</p></blockquote><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> list <span class="token operator">=</span> List<span class="token punctuation">(</span><span class="token string">&quot;Hadoop&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;Spark&quot;</span><span class="token punctuation">,</span><span class="token string">&quot;Hive&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>list<span class="token punctuation">)</span>
 
<span class="token comment">// 调用persist(MEMORY_ONLY)</span>
<span class="token comment">// 但语句执行到这里，并不会缓存rdd，因为这时rdd还没有被计算生成</span>
rdd<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment">// 第一次Action操作，触发一次真正从头到尾的计算</span>
<span class="token comment">// 这时才会执行上面的rdd.cache()，将rdd放到缓存中</span>
rdd<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
<span class="token comment">// 第二次Action操作，不需要触发从头到尾的计算</span>
<span class="token comment">// 只需要重复使用上面缓存中的rdd</span>
rdd<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">&quot;,&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p><img src="/doc/assets/README-1648780857573.896498bc.png" alt="RDD缓存"></p><blockquote><p>被缓存的RDD在DAG图中有一个绿色的圆点。</p></blockquote><h3 id="_4-4-rdd容错机制checkpoint" tabindex="-1"><a class="header-anchor" href="#_4-4-rdd容错机制checkpoint" aria-hidden="true">#</a> 4.4 RDD容错机制Checkpoint</h3><p><em>涉及到的算子: <code>checkpoint</code> ; 也是 Transformation</em></p><p>Spark中对于数据的保存除了持久化操作之外，还提供了检查点的机制;</p><p><em>检查点本质是通过将RDD写入高可靠的磁盘，主要目的是为了容错。</em></p><p>检查点通过将数据写入到HDFS文件系统实现了RDD的检查点功能。</p><p>Lineage过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，如果之后有节点出现问题而丢失分区， 从做检查点的RDD开始重做 Lineage，就会减少开销。</p><p><code>cache</code> 和 <code>checkpoint</code> 是有显著区别的，缓存把 RDD 计算出来然后放在内存中，但是 RDD 的依赖链不能丢掉， 当某个点某个 <code>executor</code> 宕了，上面 <code>cache</code> 的RDD就会丢掉，需要通过依赖链重放计算。 不同的是，<code>checkpoint</code> 是把 RDD 保存在 HDFS 中，是多副本可靠存储，此时依赖链可以丢掉，所以斩断了依赖链。</p><p>以下场景适合使用检查点机制:</p><ol><li>DAG中的Lineage过长，如果重算，则开销太大</li><li>在宽依赖上做 Checkpoint 获得的收益更大</li></ol><blockquote><p>与cache类似 checkpoint 也是 lazy 的。</p></blockquote><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">100000</span><span class="token punctuation">)</span>
 
<span class="token comment">// 设置检查点目录, 最好设置到 hdfs 上</span>
sc<span class="token punctuation">.</span>setCheckpointDir<span class="token punctuation">(</span><span class="token string">&quot;/tmp/checkpoint&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_ <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span>
rdd2<span class="token punctuation">.</span>checkpoint
 
<span class="token comment">// checkpoint 也是 lazy 操作</span>
rdd2<span class="token punctuation">.</span>isCheckpointed <span class="token comment">// false</span>
 
<span class="token comment">// checkpoint之前的rdd依赖关系</span>
rdd2<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd
rdd2<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>collect
 
<span class="token comment">// 执行一次action，触发checkpoint的执行 (此时找不到 rdd1 的依赖了，依赖关系已经被斩断了)</span>
rdd2<span class="token punctuation">.</span>count
rdd2<span class="token punctuation">.</span>isCheckpointed <span class="token comment">// true</span>
 
<span class="token comment">// 再次查看RDD的依赖关系。可以看到checkpoint后，RDD的lineage被截断，变成从checkpointRDD开始</span>
rdd2<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd
rdd2<span class="token punctuation">.</span>dependencies<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>collect
 
<span class="token comment">//查看RDD所依赖的checkpoint文件</span>
rdd2<span class="token punctuation">.</span>getCheckpointFile
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br></div></div><blockquote><p>备注: checkpoint 的文件作业执行完毕后不会被删除</p></blockquote><h3 id="_4-5-rdd的分区" tabindex="-1"><a class="header-anchor" href="#_4-5-rdd的分区" aria-hidden="true">#</a> 4.5 RDD的分区</h3><blockquote><p><code>spark.default.parallelism</code>: (默认的并发数) = 2</p></blockquote><p>当配置文件 <code>spark-default.conf</code> 中没有显示地配置，则按照如下规则取值:</p><p>1、本地模式(取决于核数)</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>spark-shell --master local<span class="token punctuation">[</span>N<span class="token punctuation">]</span> spark.default.parallelism <span class="token operator">=</span> N 
spark-shell --master <span class="token builtin class-name">local</span> spark.default.parallelism <span class="token operator">=</span> <span class="token number">1</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>2、伪分布式(x为本机上启动的executor数，y为每个executor使用的core数，z为每个executor使用的内存)</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>spark-shell --master local-cluster<span class="token punctuation">[</span>x,y,z<span class="token punctuation">]</span> spark.default.parallelism <span class="token operator">=</span> x * y
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>3、分布式模式(yarn &amp; standalone)</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>spark.default.parallelism <span class="token operator">=</span> max<span class="token punctuation">(</span>应用程序持有executor的core总数, <span class="token number">2</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><blockquote><p>total number of cores on all executor nodes or 2, whichever is larger</p></blockquote><p>经过上面的规则，就能确定了 <code>spark.default.parallelism</code> 的默认值(配置文件 <code>spark-default.conf</code> 中没有显示的配置。如果配置了，则 <code>spark.default.parallelism = 配置的值</code>)</p><hr><p><code>SparkContext</code> 初始化时，同时会生成两个参数，由上面得到的 <code>spark.default.parallelism</code> 推导出这两个参数的值</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// 从集合中创建RDD的分区数</span>
sc<span class="token punctuation">.</span>defaultParallelism <span class="token operator">=</span> spark<span class="token punctuation">.</span>default<span class="token punctuation">.</span>parallelism
<span class="token comment">// 从文件中创建RDD的分区数</span>
sc<span class="token punctuation">.</span>defaultMinPartitions <span class="token operator">=</span> min<span class="token punctuation">(</span>spark<span class="token punctuation">.</span>default<span class="token punctuation">.</span>parallelism<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>以上参数确定后，就可以计算 RDD 的分区数了。</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">/**
 * Default min number of partitions for Hadoop RDDs when not given by user
 * Notice that we use math.min so the &quot;defaultMinPartitions&quot; cannot be higher than 2.
 * The reasons for this are discussed in https://github.com/mesos/spark/pull/718
 */</span>
<span class="token keyword">def</span> defaultMinPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> math<span class="token punctuation">.</span>min<span class="token punctuation">(</span>defaultParallelism<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><hr><h4 id="创建-rdd-的几种方式" tabindex="-1"><a class="header-anchor" href="#创建-rdd-的几种方式" aria-hidden="true">#</a> 创建 RDD 的几种方式</h4><p>1、通过集合创建</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token comment">// 如果创建RDD时没有指定分区数，则rdd的分区数 = sc.defaultParallelism </span>
<span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">100</span><span class="token punctuation">)</span>
rdd<span class="token punctuation">.</span>getNumPartitions
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><blockquote><p>备注: 简单的说RDD分区数等于cores总数</p></blockquote><p>2、通过textFile创建</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;data/start0721.big.log&quot;</span><span class="token punctuation">)</span> 
rdd<span class="token punctuation">.</span>getNumPartitions
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>如果没有指定分区数:</p><ul><li>本地文件。<code>rdd的分区数 = max(本地文件分片数, sc.defaultMinPartitions)</code></li><li>HDFS文件。 <code>rdd的分区数 = max(hdfs文件 block 数, sc.defaultMinPartitions)</code></li></ul><p>备注:</p><ul><li><code>本地文件分片数 = 本地文件大小 / 32M</code></li><li>如果读取的是HDFS文件，同时指定的分区数 &lt; hdfs文件的block数，指定的数不生效。</li></ul><h3 id="_4-6-rdd分区器" tabindex="-1"><a class="header-anchor" href="#_4-6-rdd分区器" aria-hidden="true">#</a> 4.6 RDD分区器</h3><blockquote><p>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</p></blockquote><p><em>只有Key-Value类型的RDD才可能有分区器，Value类型的RDD分区器的值是 None。</em></p><hr><p>以下RDD分别是否有分区器，是什么类型的分区器?</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;/wcinput/wc.txt&quot;</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>partitioner <span class="token comment">// None</span>

<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\\s+&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
rdd2<span class="token punctuation">.</span>partitioner <span class="token comment">// None</span>

<span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
rdd3<span class="token punctuation">.</span>partitioner <span class="token comment">// None</span>

<span class="token keyword">val</span> rdd4 <span class="token operator">=</span> rdd3<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
rdd4<span class="token punctuation">.</span>partitioner <span class="token comment">// Some(org.apache.spark.HashPartitioner@2)</span>

<span class="token keyword">val</span> rdd5 <span class="token operator">=</span> rdd4<span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
rdd5<span class="token punctuation">.</span>partitioner <span class="token comment">// Some(org.apache.spark.RangePartitioner@e44e9b0e)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><hr><p><strong>分区器的作用及分类</strong></p><p>在 <code>PairRDD(key,value)</code> 中，很多操作都是基于key的，系统会按照key对数据进行重组，如 <code>groupByKey</code>;</p><p>数据重组需要规则，最常见的就是基于 Hash 的分区，此外还有一种复杂的基于抽样 Range 分区方法;</p><p><img src="/doc/assets/README-1648711921567.a1320010.png" alt="基于抽样的分区"></p><h4 id="hashpartitioner" tabindex="-1"><a class="header-anchor" href="#hashpartitioner" aria-hidden="true">#</a> HashPartitioner</h4><p>最简单、最常用，也是默认提供的分区器。</p><p>对于给定的key，计算其hashCode，并除以分区的个数取余，如果余数小于0，则用 <code>余数+分区的个数</code>， 最后返回的值就是这个key所属的分区ID。该分区方法可以保证key相同的数据出现在同一个分区中。</p><p>用户可通过 <code>partitionBy</code> 主动使用分区器，通过 <code>partitions</code> 参数指定想要分区的数量。</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>getNumPartitions <span class="token comment">// 6</span>

<span class="token comment">// 仅仅是将数据大致平均分成了若干份; rdd并没有分区器</span>
rdd1<span class="token punctuation">.</span>glom<span class="token punctuation">.</span>collect<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> println<span class="token punctuation">(</span>x<span class="token punctuation">.</span>toBuffer<span class="token punctuation">)</span><span class="token punctuation">)</span>
rdd1<span class="token punctuation">.</span>partitioner <span class="token comment">// None</span>

<span class="token comment">// 主动使用 HashPartitioner</span>
<span class="token keyword">val</span> rdd2 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>HashPartitioner<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
rdd2<span class="token punctuation">.</span>glom<span class="token punctuation">.</span>collect<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> println<span class="token punctuation">(</span>x<span class="token punctuation">.</span>toBuffer<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">// 主动使用 HashPartitioner</span>
<span class="token keyword">val</span> rdd3 <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>RangePartitioner<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> rdd1<span class="token punctuation">)</span><span class="token punctuation">)</span>
rdd3<span class="token punctuation">.</span>glom<span class="token punctuation">.</span>collect<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> println<span class="token punctuation">(</span>x<span class="token punctuation">.</span>toBuffer<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><blockquote><p>大多数时候我们都是被动使用的分区器。</p></blockquote><p>Spark的很多算子都可以设置 HashPartitioner 的值</p><p><img src="/doc/assets/README-1648712103089.e594e11e.png" alt="修改Partitioner的算子"></p><h4 id="rangepartitioner" tabindex="-1"><a class="header-anchor" href="#rangepartitioner" aria-hidden="true">#</a> RangePartitioner</h4><p>简单的说就是将一定范围内的数映射到某一个分区内。</p><p>在实现中，分界的算法尤为重要，用到了水塘抽样算法。</p><p><code>sortByKey</code> 会使用 RangePartitioner。</p><p><img src="/doc/assets/README-1648712191324.51a4f4e2.png" alt="sortByKey示意图"></p><p>现在的问题: 在执行分区之前其实并不知道数据的分布情况，如果想知道数据分区就需要对数据进行采样;</p><p>Spark 中 RangePartitioner 在对数据采样的过程中使用了<strong>水塘采样算法</strong>。</p><blockquote><p>水塘采样: 从包含n个项目的集合S中选取k个样本，其中n为一很大或未知的数量，尤其适用于不能把所有n个项目都存放到主内存的情况;</p></blockquote><p>在采样的过程中执行了 <code>collect()</code> 操作，引发了Action操作。</p><blockquote><p>也就是说，非常严格来讲，并不是所有的 Transformation 都不会触发 Action。</p></blockquote><h4 id="自定义分区器" tabindex="-1"><a class="header-anchor" href="#自定义分区器" aria-hidden="true">#</a> 自定义分区器</h4><p>Spark允许用户通过自定义的Partitioner对象，灵活的来控制RDD的分区方式。</p><p>实现自定义分区器按以下规则分区:</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>分区0 &lt; 100
100 &lt;= 分区1 &lt; 200 
200 &lt;= 分区2 &lt; 300 
300 &lt;= 分区3 &lt; 400 
... ...
900 &lt;= 分区9 &lt; 1000
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">class</span> MyPartitioner<span class="token punctuation">(</span>n<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> Partitioner<span class="token punctuation">{</span>
  <span class="token comment">// 有多少个分区数</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> numPartitions<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    n
  <span class="token punctuation">}</span>

  <span class="token comment">// 给定 key，如何分区</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> getPartition<span class="token punctuation">(</span>key<span class="token operator">:</span> <span class="token builtin">Any</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> k<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> key<span class="token punctuation">.</span>toString<span class="token punctuation">.</span>toInt
    k <span class="token operator">/</span> <span class="token number">100</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">object</span> UserDefinePartitioner <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">// 1.创建 SparkContext</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getSimpleName<span class="token punctuation">.</span>init<span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;WARN&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">// 业务逻辑</span>
    <span class="token keyword">val</span> random<span class="token operator">:</span> Random<span class="token punctuation">.</span><span class="token keyword">type</span> <span class="token operator">=</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random
    <span class="token keyword">val</span> arr<span class="token operator">:</span> immutable<span class="token punctuation">.</span>IndexedSeq<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>_ <span class="token keyword">=&gt;</span> random<span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>arr<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    rdd1<span class="token punctuation">.</span>glom<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> println<span class="token punctuation">(</span>x<span class="token punctuation">.</span>toBuffer<span class="token punctuation">)</span><span class="token punctuation">)</span>

    println<span class="token punctuation">(</span><span class="token string">&quot;--------------------------------------------&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> rdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token keyword">new</span> MyPartitioner<span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    rdd2<span class="token punctuation">.</span>glom<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>x <span class="token keyword">=&gt;</span> println<span class="token punctuation">(</span>x<span class="token punctuation">.</span>toBuffer<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// 5.关闭 SparkContext</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br></div></div><h3 id="_4-7-广播变量" tabindex="-1"><a class="header-anchor" href="#_4-7-广播变量" aria-hidden="true">#</a> 4.7 广播变量</h3><p>有时候需要在多个任务之间共享变量，或者在任务(Task)和Driver Program之间<em>共享变量</em>。 为了满足这种需求，Spark提供了两种类型的变量:</p><ul><li>广播变量(broadcast variables)</li><li>累加器(accumulators)</li></ul><p><strong>广播变量、累加器主要作用是为了优化Spark程序</strong>。</p><p>广播变量将变量在节点的 Executor 之间进行共享(由Driver广播出去);</p><p>广播变量用来高效分发较大的对象。向所有工作节点(Executor)发送一个较大的只读值，以供一个或多个操作使用。</p><p>使用广播变量的过程如下:</p><ul><li><p>对一个类型 T 的对象调用 <code>SparkContext.broadcast</code> 创建出一个 <code>Broadcast[T]</code> 对象。 任何可序列化的类型都可以这么实现(在 Driver 端)</p></li><li><p>通过 <code>value</code> 属性访问该对象的值(在 Executor 中)</p></li><li><p>变量值会被发到各个 Executor 一次，作为只读值处理。</p></li></ul><p><img src="/doc/assets/README-1648712542133.2189892e.png" alt="广播变量示意图"></p><p>广播变量的优化：</p><ol><li>整个 Executor 共享一份</li><li>传输的时候要做压缩 (注意需要序列化和反序列化)</li><li>使用 BT 传输协议</li></ol><blockquote><p>BT 传输协议：简单讲主要有两点，一是会将数据按块切分，二是并不是所有的数据块都找 Driver 要。</p></blockquote><p>广播变量的相关参数</p><table><thead><tr><th>参数</th><th>含义</th><th>默认值</th></tr></thead><tbody><tr><td>spark.broadcast.blockSize</td><td>对广播变量分块的块大小</td><td>4m</td></tr><tr><td>spark.broadcast.checksum</td><td>数据检验</td><td>true</td></tr><tr><td>spark.broadcast.compress</td><td>是否压缩</td><td>true</td></tr></tbody></table><h4 id="广播变量的运用-map-side-join" tabindex="-1"><a class="header-anchor" href="#广播变量的运用-map-side-join" aria-hidden="true">#</a> 广播变量的运用(Map Side Join)</h4><p>普通的Join操作</p><p><img src="/doc/assets/README-1648712672009.37f698fd.png" alt="普通的Join操作"></p><p>Map Side Join</p><p><img src="/doc/assets/README-1648712712716.555b4e45.png" alt="MapSideJoin"></p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">object</span> JoinDemo <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getCanonicalName<span class="token punctuation">.</span>init<span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token comment">// 设置本地文件切分大小(本地文件默认切块大小 32m)</span>
    sc<span class="token punctuation">.</span>hadoopConfiguration<span class="token punctuation">.</span>setLong<span class="token punctuation">(</span><span class="token string">&quot;fs.local.block.size&quot;</span><span class="token punctuation">,</span> <span class="token number">128</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token punctuation">)</span>

    <span class="token comment">// map task：数据准备 (此处将配置文件更名为 core-site.xml.bak 让其失效，从而读本地文件)</span>
    <span class="token keyword">val</span> productRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;data/product_info.txt&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map <span class="token punctuation">{</span> line <span class="token keyword">=&gt;</span>
        <span class="token keyword">val</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;;&quot;</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>fields<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

    <span class="token keyword">val</span> orderRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;data/orderinfo.txt&quot;</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map <span class="token punctuation">{</span> line <span class="token keyword">=&gt;</span>
        <span class="token keyword">val</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;;&quot;</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>fields<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

    <span class="token comment">// join有shuffle操作</span>
    <span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> productRDD<span class="token punctuation">.</span>join<span class="token punctuation">(</span>orderRDD<span class="token punctuation">)</span>

    println<span class="token punctuation">(</span>resultRDD<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    Thread<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1000000</span><span class="token punctuation">)</span>

    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p><img src="/doc/assets/README-1648793963757.a2405005.png" alt="Join执行"></p><p>执行时间21s，shuffle read 450M (CPU: i7-8750H)</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">object</span> MapSideJoin <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getCanonicalName<span class="token punctuation">.</span>init<span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token comment">// 设置本地文件切分大小</span>
    sc<span class="token punctuation">.</span>hadoopConfiguration<span class="token punctuation">.</span>setLong<span class="token punctuation">(</span><span class="token string">&quot;fs.local.block.size&quot;</span><span class="token punctuation">,</span> <span class="token number">128</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token punctuation">)</span>

    <span class="token comment">// map task：数据准备</span>
    <span class="token keyword">val</span> productMap<span class="token operator">:</span> collection<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;data/product_info.txt&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map <span class="token punctuation">{</span> line <span class="token keyword">=&gt;</span>
        <span class="token keyword">val</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;;&quot;</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>fields<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">.</span>collectAsMap<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// 广播商品信息</span>
    <span class="token keyword">val</span> productBC<span class="token operator">:</span> Broadcast<span class="token punctuation">[</span>collection<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>productMap<span class="token punctuation">)</span>

    <span class="token keyword">val</span> orderRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">&quot;data/orderinfo.txt&quot;</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map <span class="token punctuation">{</span> line <span class="token keyword">=&gt;</span>
        <span class="token keyword">val</span> fields <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;;&quot;</span><span class="token punctuation">)</span>
        <span class="token punctuation">(</span>fields<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

    <span class="token comment">// 完成 map side join 操作</span>
    <span class="token comment">// RDD[(String, (String, String))]: (pid, (productInfo, orderInfo))</span>
    <span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> orderRDD<span class="token punctuation">.</span>map <span class="token punctuation">{</span> <span class="token keyword">case</span> <span class="token punctuation">(</span>pid<span class="token punctuation">,</span> orderInfo<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
      <span class="token keyword">val</span> prodMap<span class="token operator">:</span> collection<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> productBC<span class="token punctuation">.</span>value
      <span class="token keyword">val</span> productInfo<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> prodMap<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>pid<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span>pid<span class="token punctuation">,</span> <span class="token punctuation">(</span>productInfo<span class="token punctuation">,</span> orderInfo<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

    println<span class="token punctuation">(</span>resultRDD<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    Thread<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1000000</span><span class="token punctuation">)</span>

    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="highlight-lines"><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><div class="highlight-line"> </div><br><br><br><br><br><br><br><br><br><div class="highlight-line"> </div><div class="highlight-line"> </div><div class="highlight-line"> </div><div class="highlight-line"> </div><div class="highlight-line"> </div><br><br><br><br><br><br><br><br></div><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br></div></div><p>执行时间5s，没有shuffle (CPU: i7-8750H)</p><p><img src="/doc/assets/README-1648794860042.f08960a1.png" alt="Map端Join"></p><h3 id="_4-8-累加器" tabindex="-1"><a class="header-anchor" href="#_4-8-累加器" aria-hidden="true">#</a> 4.8 累加器</h3><p>累加器的作用: 可以实现一个变量在不同的 Executor 端能保持状态的累加;</p><p>累计器在 Driver 端定义、读取; 在 Executor 中完成累加;</p><p>累加器也是 lazy 的，需要 Action 触发; Action触发一次，执行一次，触发多次，执行多次;</p><p>累加器一个比较经典的应用场景是用来在 Spark Streaming 应用中记录某些事件的数量;</p><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> data <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>Seq<span class="token punctuation">(</span><span class="token string">&quot;hadoop map reduce&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;spark mllib&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
<span class="token comment">// 方式1</span>
<span class="token keyword">val</span> count1 <span class="token operator">=</span> data<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>line <span class="token keyword">=&gt;</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\\s+&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>word <span class="token keyword">=&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduce<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
println<span class="token punctuation">(</span>count1<span class="token punctuation">)</span>

<span class="token comment">// 方式2。错误的方式, 下面的打印的是driver端的acc 仍然是0</span>
<span class="token keyword">var</span> acc <span class="token operator">=</span> <span class="token number">0</span>
data<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>line <span class="token keyword">=&gt;</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\\s+&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>word <span class="token keyword">=&gt;</span> acc <span class="token operator">+=</span> <span class="token number">1</span><span class="token punctuation">)</span>
println<span class="token punctuation">(</span>acc<span class="token punctuation">)</span>
 
<span class="token comment">// 在Driver中定义变量，每个运行的Task会得到这些变量的一份新的副本，</span>
<span class="token comment">// 但在Task中更新这些副本的值不会影响Driver中对应变量的值</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>Spark内置了三种类型的累加器，分别是:</p><ul><li><code>LongAccumulator</code> 用来累加整数型</li><li><code>DoubleAccumulator</code> 用来累加浮点型</li><li><code>CollectionAccumulator</code> 用来累加集合元素</li></ul><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">val</span> data <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span><span class="token string">&quot;hadoop spark hive hbase java scala hello world spark scala java hive&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;\\s+&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 
<span class="token keyword">val</span> acc1 <span class="token operator">=</span> sc<span class="token punctuation">.</span>longAccumulator<span class="token punctuation">(</span><span class="token string">&quot;totalNum1&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> acc2 <span class="token operator">=</span> sc<span class="token punctuation">.</span>doubleAccumulator<span class="token punctuation">(</span><span class="token string">&quot;totalNum2&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">val</span> acc3 <span class="token operator">=</span> sc<span class="token punctuation">.</span>collectionAccumulator<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">&quot;allWords&quot;</span><span class="token punctuation">)</span>
 
<span class="token comment">// 因为count和collect触发了两次 Action, 下面的统计会执行两次</span>
<span class="token keyword">val</span> rdd <span class="token operator">=</span> data<span class="token punctuation">.</span>map <span class="token punctuation">{</span> word <span class="token keyword">=&gt;</span>
    acc1<span class="token punctuation">.</span>add<span class="token punctuation">(</span>word<span class="token punctuation">.</span>length<span class="token punctuation">)</span>
    acc2<span class="token punctuation">.</span>add<span class="token punctuation">(</span>word<span class="token punctuation">.</span>length<span class="token punctuation">)</span>
    acc3<span class="token punctuation">.</span>add<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
    word
<span class="token punctuation">}</span>
 
rdd<span class="token punctuation">.</span>count
rdd<span class="token punctuation">.</span>collect
 
println<span class="token punctuation">(</span>acc1<span class="token punctuation">.</span>value<span class="token punctuation">)</span>
println<span class="token punctuation">(</span>acc2<span class="token punctuation">.</span>value<span class="token punctuation">)</span>
println<span class="token punctuation">(</span>acc3<span class="token punctuation">.</span>value<span class="token punctuation">)</span>
</code></pre><div class="highlight-lines"><br><br><br><br><br><br><div class="highlight-line"> </div><br><br><br><br><br><br><br><br><br><br><br><br><br></div><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><blockquote><p>要非常注意，一不小心就容易执行两次 Action，从而让累加的结果出乎我们的意料。</p></blockquote><h3 id="_4-9-topn的优化" tabindex="-1"><a class="header-anchor" href="#_4-9-topn的优化" aria-hidden="true">#</a> 4.9 TopN的优化</h3><div class="language-scala ext-scala line-numbers-mode"><pre class="language-scala"><code><span class="token keyword">object</span> TopN <span class="token punctuation">{</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">// 1.创建 SparkContext</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getSimpleName<span class="token punctuation">.</span>init<span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>setLogLevel<span class="token punctuation">(</span><span class="token string">&quot;WARN&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> N <span class="token operator">=</span> <span class="token number">9</span>

    <span class="token comment">// 生成数据</span>
    <span class="token keyword">val</span> random <span class="token operator">=</span> scala<span class="token punctuation">.</span>util<span class="token punctuation">.</span>Random
    <span class="token keyword">val</span> scores<span class="token operator">:</span> immutable<span class="token punctuation">.</span>IndexedSeq<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatMap <span class="token punctuation">{</span> idx <span class="token keyword">=&gt;</span>
      <span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map <span class="token punctuation">{</span> _ <span class="token keyword">=&gt;</span>
        <span class="token string-interpolation"><span class="token id function">f</span><span class="token string">&quot;group</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">idx</span></span><span class="token string">%2d,</span><span class="token interpolation"><span class="token punctuation">${</span><span class="token expression">random<span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span><span class="token number">100000</span><span class="token punctuation">)</span></span><span class="token punctuation">}</span></span><span class="token string">&quot;</span></span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    <span class="token comment">// scores.foreach(println)</span>

    <span class="token keyword">val</span> scoreRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token punctuation">.</span>map <span class="token punctuation">{</span> line <span class="token keyword">=&gt;</span>
      <span class="token keyword">val</span> fields<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">&quot;,&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span>fields<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fields<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    scoreRDD<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// TopN 的实现</span>
    <span class="token comment">// groupByKey 的实现：需要将每个分区的每个 Group 的全部数据做 Shuffle</span>
    scoreRDD<span class="token punctuation">.</span>groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>mapValues<span class="token punctuation">(</span>buf <span class="token keyword">=&gt;</span> buf<span class="token punctuation">.</span>toList<span class="token punctuation">.</span>sorted<span class="token punctuation">.</span>takeRight<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">.</span>reverse<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    println<span class="token punctuation">(</span><span class="token string">&quot;-------------------------------&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">// TopN 的优化</span>
    scoreRDD<span class="token punctuation">.</span>aggregateByKey<span class="token punctuation">(</span>List<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>
      <span class="token punctuation">(</span>lst<span class="token punctuation">,</span> score<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>lst <span class="token operator">:</span><span class="token operator">+</span> score<span class="token punctuation">)</span><span class="token punctuation">.</span>sorted<span class="token punctuation">.</span>takeRight<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">// 分区内取 TopN</span>
      <span class="token punctuation">(</span>lst1<span class="token punctuation">,</span> lst2<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>lst1 <span class="token operator">++</span> lst2<span class="token punctuation">)</span><span class="token punctuation">.</span>sorted<span class="token punctuation">.</span>takeRight<span class="token punctuation">(</span>N<span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">.</span>mapValues<span class="token punctuation">(</span>buf <span class="token keyword">=&gt;</span> buf<span class="token punctuation">.</span>reverse<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>sortByKey<span class="token punctuation">(</span>ascending <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    <span class="token comment">// 5.关闭 SparkContext</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="highlight-lines"><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><div class="highlight-line"> </div><div class="highlight-line"> </div><div class="highlight-line"> </div><div class="highlight-line"> </div><div class="highlight-line"> </div><div class="highlight-line"> </div><div class="highlight-line"> </div><br><br><br><br><br></div><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br></div></div><blockquote><p>使用 <code>aggregateByKey</code> 替换 <code>groupByKey</code>, 核心思想就是：如果 Shuffle 不可避免， 可以减少 Shuffle 的数据量来提高性能。</p></blockquote><h2 id="第5节-spark原理初探" tabindex="-1"><a class="header-anchor" href="#第5节-spark原理初探" aria-hidden="true">#</a> 第5节 Spark原理初探</h2><h3 id="_5-1-standalone模式作业提交" tabindex="-1"><a class="header-anchor" href="#_5-1-standalone模式作业提交" aria-hidden="true">#</a> 5.1 Standalone模式作业提交</h3><p>Standalone 模式下有四个重要组成部分，分别是:</p><ul><li>Driver: 用户编写的 Spark 应用程序就运行在 Driver 上，由Driver 进程执行</li><li>Master: 主要负责资源的调度和分配，并进行集群的监控等职责</li><li>Worker: Worker 运行在集群中的一台服务器上。负责管理该节点上的资源，负责启动启动节点上的 Executor</li><li>Executor: 一个 Worker 上可以运行多个 Executor，Executor通过启动多个线程(task)对 RDD 的分区进行并行计算</li></ul><p>SparkContext 中的三大组件:</p><ul><li>DAGScheduler: 负责将DAG划分成若干个Stage</li><li>TaskScheduler: 将DAGScheduler提交的Stage(TaskSet)进行优先级排序，再将 task 发送到 Executor</li><li>SchedulerBackend: 定义了许多与Executor事件相关的处理，包括: 新的 executor 注册进来的时候记录executor的信息， 增加全局的资源量(核数); executor 更新状态，若任务完成的话，回收core; 其他停止executor、remove executor等事件</li></ul><p><img src="/doc/assets/README-1648713236052.0b678477.png" alt="SparkContext三大组件"></p><p>Standalone模式下作业提交步骤:</p><ol><li>启动应用程序，完成SparkContext的初始化</li><li>Driver向Master注册，申请资源</li><li>Master检查集群资源状况。若集群资源满足，通知Worker启动Executor</li><li>Executor启动后向Driver注册(称为反向注册)</li><li>Driver完成DAG的解析，得到Tasks，然后向Executor发送Task</li><li>Executor 向Driver汇总任务的执行情况</li><li>应用程序执行完毕，回收资源</li></ol><p><img src="/doc/assets/README-1648713313870.f0398dbc.png" alt="Standalone作业提交步骤"></p><h3 id="_5-2-shuffle原理" tabindex="-1"><a class="header-anchor" href="#_5-2-shuffle原理" aria-hidden="true">#</a> 5.2 Shuffle原理</h3><p>Shuffle的本意是洗牌，目的是为了把牌弄乱。</p><p>Spark、Hadoop中的shuffle可不是为了把数据弄乱，而是为了将随机排列的数据转换成具有一定规则的数据。</p><p>Shuffle 是MapReduce计算框架中的一个特殊的阶段，介于 Map 和 Reduce 之间。 当Map的输出结果要被Reduce使用时，输出结果需要按key排列，并且分发到 Reducer 上去，这个过程就是shuffle。</p><p>Shuffle 涉及到了本地磁盘(非HDFS)的读写和网络的传输，大多数Spark作业的性能主要就是消耗在了shuffle环节。 因此Shuffle性能的高低直接影响到了整个程序的运行效率。</p><p>在Spark Shuffle的实现上，经历了Hash Shuffle、Sort Shuffle、Unsafe Shuffle三阶段:</p><ul><li>Spark 0.8 及以前 Hash Based Shuffle</li><li>Spark 0.8.1 为Hash Based Shuffle引入File Consolidation机制 Spark 0.9 引入ExternalAppendOnlyMap</li><li>Spark 1.1 引入Sort Based Shuffle，但默认仍为Hash Based Shuffle</li><li>Spark 1.2 默认的Shuffle方式改为Sort Based Shuffle</li><li>Spark 1.4 引入Tungsten-Sort Based Shuffle(可以使用堆外内存)</li><li>Spark 1.6 Tungsten-sort并入Sort Based Shuffle</li><li>Spark 2.0 Hash Based Shuffle退出历史舞台</li></ul><p>简单的说:</p><ul><li>Spark 1.1 以前是Hash Shuffle</li><li>Spark 1.1 引入了Sort Shuffle(此时和 MR 的 Shuffle 已经非常相似了)</li><li>Spark 1.6 将Tungsten-sort并入Sort Shuffle</li><li>Spark 2.0 Hash Shuffle退出历史舞台</li></ul><p><img src="/doc/assets/README-1648713511741.f30bb9ab.png" alt="SparkShuffle发展进程"></p><h4 id="_1、hash-base-shuffle-v1" tabindex="-1"><a class="header-anchor" href="#_1、hash-base-shuffle-v1" aria-hidden="true">#</a> 1、Hash Base Shuffle V1</h4><p>每个Shuffle Map Task需要为每个下游的Task创建一个单独的文件</p><p>Shuffle过程中会生成海量的小文件。同时打开过多文件、低效的随机IO</p><p><img src="/doc/assets/README-1648713688586.4e6a5bf2.png" alt="HashBaseV1"></p><h4 id="_2、hash-base-shuffle-v2" tabindex="-1"><a class="header-anchor" href="#_2、hash-base-shuffle-v2" aria-hidden="true">#</a> 2、Hash Base Shuffle V2</h4><p>Hash Base Shuffle V2 核心思想: 允许不同的task复用同一批磁盘文件，有效将多个 task的磁盘文件进行一定程度上的合并， 从而大幅度减少磁盘文件的数量，进而提升 shuffle write 的性能。一定程度上解决了Hash V1中的问题，但不彻底。</p><p><img src="/doc/assets/README-1648713708710.0ca9de5b.png" alt="HashBaseV2"></p><p>Hash Shuffle 规避了排序，提高了性能; 总的来说在Hash Shuffle过程中生成海量的小文件 (Hash Base Shuffle V2生成海量小文件的问题得到了一定程度的缓解)。</p><h4 id="_3、sort-base-shuffle" tabindex="-1"><a class="header-anchor" href="#_3、sort-base-shuffle" aria-hidden="true">#</a> 3、Sort Base Shuffle</h4><p>Sort Base Shuffle大大减少了shuffle过程中产生的文件数，提高Shuffle的效率;</p><p><img src="/doc/assets/README-1648713731355.365f1f9a.png" alt="SortBase"></p><blockquote><p>Spark Shuffle 与 Hadoop Shuffle 从目的、意义、功能上看是类似的，实现(细节)上有区别。</p></blockquote><h3 id="_5-3-rdd编程优化" tabindex="-1"><a class="header-anchor" href="#_5-3-rdd编程优化" aria-hidden="true">#</a> 5.3 RDD编程优化</h3><h4 id="_5-3-1-rdd复用" tabindex="-1"><a class="header-anchor" href="#_5-3-1-rdd复用" aria-hidden="true">#</a> 5.3.1 RDD复用</h4><p>避免创建重复的RDD。在开发过程中要注意: 对于同一份数据，只应该创建一个 RDD，不要创建多个RDD来代表同一份数据。</p><h4 id="_5-3-2-rdd缓存-持久化" tabindex="-1"><a class="header-anchor" href="#_5-3-2-rdd缓存-持久化" aria-hidden="true">#</a> 5.3.2 RDD缓存/持久化</h4><p>当多次对同一个RDD执行算子操作时，每一次都会对这个RDD以之前的父RDD重新计算一次，这种情况是必须要避免的， 对同一个RDD的重复计算是对资源的极大浪费</p><p>对多次使用的RDD进行持久化，通过持久化将公共RDD的数据缓存到内存/磁盘中，之后对于公共RDD的计算都会从内存/磁盘中直接获取RDD数据</p><p>RDD的持久化是可以进行序列化的，当内存无法将RDD的数据完整的进行存放的时候，可以考虑使用序列化的方式减小数据体积，将数据完整存储在内存中</p><h4 id="_5-3-3-巧用-filter" tabindex="-1"><a class="header-anchor" href="#_5-3-3-巧用-filter" aria-hidden="true">#</a> 5.3.3 巧用 filter</h4><p>尽可能早的执行filter操作，过滤无用数据</p><p>在filter过滤掉较多数据后，使用 <code>coalesce</code> 对数据进行重分区</p><h4 id="_5-3-4-使用高性能算子" tabindex="-1"><a class="header-anchor" href="#_5-3-4-使用高性能算子" aria-hidden="true">#</a> 5.3.4 使用高性能算子</h4><ol><li>避免使用 <code>groupByKey</code>，根据场景选择使用高性能的聚合算子 <code>reduceByKey</code>、 <code>aggregateByKey</code></li><li><code>coalesce</code>、<code>repartition</code>，在可能的情况下优先选择没有shuffle的操作(<code>coalesce</code>)</li><li><code>foreachPartition</code> 优化输出操作</li><li><code>map</code>、<code>mapPartitions</code>，选择合理的选择算子 <code>mapPartitions</code> 性能更好(作用于数据分区上)，但数据量大时容易导致OOM</li><li>用 <code>repartitionAndSortWithinPartitions</code> 替代 <code>repartition + sort</code> 操作(将两次 Shuffle 减少为一次)</li><li>合理使用 <code>cache</code>、<code>persist</code>、<code>checkpoint</code>，选择合理的数据存储级别</li><li><code>filter</code> 的使用</li><li>减少对数据源的扫描(算法复杂了)</li></ol><h4 id="_5-3-5-设置合理的并行度" tabindex="-1"><a class="header-anchor" href="#_5-3-5-设置合理的并行度" aria-hidden="true">#</a> 5.3.5 设置合理的并行度</h4><p>Spark作业中的并行度指各个stage的task的数量</p><p>设置合理的并行度，让并行度与资源相匹配。简单来说就是在资源允许的前提下，并行度要设置的尽可能大， 达到可以充分利用集群资源。合理的设置并行度，可以提升整个Spark作业的性能和运行速度。</p><h4 id="_5-3-6-广播大变量" tabindex="-1"><a class="header-anchor" href="#_5-3-6-广播大变量" aria-hidden="true">#</a> 5.3.6 广播大变量</h4><p>默认情况下，task中的算子中如果使用了外部变量，每个task都会获取一份变量的复本， 这会造多余的网络传输和内存消耗</p><p>使用广播变量，只会在每个Executor保存一个副本，Executor的所有task共用此广播变量， 这样就节约了网络及内存资源</p><!--]--></div><footer class="page-meta"><div class="meta-item edit-link"><a class="external-link meta-item-label" href="https://github.com/faustine8/doc/edit/main/docs/bigdata/spark/core/rdd2/README.md" rel="noopener noreferrer" target="_blank" aria-label="在 GitHub 上编辑"><!--[--><!--]--> 在 GitHub 上编辑 <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><div class="meta-item last-updated"><span class="meta-item-label">更新时间: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">贡献者: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: faustine923@icloud.com">mujunlin</span><!----><!--]--><!--]--></span></div></footer><!----><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/doc/assets/app.40df414d.js" defer></script>
  </body>
</html>
