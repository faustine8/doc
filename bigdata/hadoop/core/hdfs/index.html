<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.42">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <title>5. HDFS分布式文件系统 | zmn.cn</title><meta name="description" content="后端开发知识库">
    <link rel="modulepreload" href="/doc/assets/app.40df414d.js"><link rel="modulepreload" href="/doc/assets/index.html.3472a443.js"><link rel="modulepreload" href="/doc/assets/index.html.e2de7b5a.js"><link rel="prefetch" href="/doc/assets/index.html.ac157e58.js"><link rel="prefetch" href="/doc/assets/index.html.795c9140.js"><link rel="prefetch" href="/doc/assets/index.html.fd51b8b2.js"><link rel="prefetch" href="/doc/assets/index.html.0c15a99b.js"><link rel="prefetch" href="/doc/assets/index.html.0c59ef61.js"><link rel="prefetch" href="/doc/assets/index.html.f10e9c63.js"><link rel="prefetch" href="/doc/assets/index.html.b5bfa26a.js"><link rel="prefetch" href="/doc/assets/index.html.e8912321.js"><link rel="prefetch" href="/doc/assets/index.html.e524e2c7.js"><link rel="prefetch" href="/doc/assets/index.html.e2c03529.js"><link rel="prefetch" href="/doc/assets/index.html.1a75e17e.js"><link rel="prefetch" href="/doc/assets/index.html.27d315d2.js"><link rel="prefetch" href="/doc/assets/index.html.8527be29.js"><link rel="prefetch" href="/doc/assets/index.html.5603dc63.js"><link rel="prefetch" href="/doc/assets/index.html.a735b5dd.js"><link rel="prefetch" href="/doc/assets/index.html.68217935.js"><link rel="prefetch" href="/doc/assets/index.html.79799519.js"><link rel="prefetch" href="/doc/assets/index.html.6881f0e6.js"><link rel="prefetch" href="/doc/assets/index.html.e7ff66c5.js"><link rel="prefetch" href="/doc/assets/index.html.b3989c09.js"><link rel="prefetch" href="/doc/assets/index.html.90a11c7e.js"><link rel="prefetch" href="/doc/assets/index.html.e552d764.js"><link rel="prefetch" href="/doc/assets/index.html.a2e921be.js"><link rel="prefetch" href="/doc/assets/index.html.40de4d57.js"><link rel="prefetch" href="/doc/assets/index.html.8dfb5661.js"><link rel="prefetch" href="/doc/assets/index.html.0b633e02.js"><link rel="prefetch" href="/doc/assets/index.html.325a81ac.js"><link rel="prefetch" href="/doc/assets/index.html.fc94b663.js"><link rel="prefetch" href="/doc/assets/index.html.a61a14dc.js"><link rel="prefetch" href="/doc/assets/index.html.915b115c.js"><link rel="prefetch" href="/doc/assets/index.html.74c3962d.js"><link rel="prefetch" href="/doc/assets/index.html.50e666c4.js"><link rel="prefetch" href="/doc/assets/index.html.bd0865d1.js"><link rel="prefetch" href="/doc/assets/index.html.670a8d54.js"><link rel="prefetch" href="/doc/assets/index.html.267a5925.js"><link rel="prefetch" href="/doc/assets/index.html.820a240a.js"><link rel="prefetch" href="/doc/assets/index.html.956e3861.js"><link rel="prefetch" href="/doc/assets/index.html.1eb9b84f.js"><link rel="prefetch" href="/doc/assets/index.html.085c7b3b.js"><link rel="prefetch" href="/doc/assets/index.html.cc6b0c3f.js"><link rel="prefetch" href="/doc/assets/index.html.878a89e3.js"><link rel="prefetch" href="/doc/assets/index.html.4349d3a7.js"><link rel="prefetch" href="/doc/assets/index.html.ad70fd8f.js"><link rel="prefetch" href="/doc/assets/index.html.ae8f6e96.js"><link rel="prefetch" href="/doc/assets/index.html.5904c85d.js"><link rel="prefetch" href="/doc/assets/index.html.67ad7772.js"><link rel="prefetch" href="/doc/assets/index.html.1fb78180.js"><link rel="prefetch" href="/doc/assets/index.html.79837727.js"><link rel="prefetch" href="/doc/assets/index.html.3b548d45.js"><link rel="prefetch" href="/doc/assets/index.html.3a65bcaf.js"><link rel="prefetch" href="/doc/assets/index.html.636ab4d4.js"><link rel="prefetch" href="/doc/assets/index.html.8c20145c.js"><link rel="prefetch" href="/doc/assets/index.html.93d3f714.js"><link rel="prefetch" href="/doc/assets/index.html.5cc28277.js"><link rel="prefetch" href="/doc/assets/index.html.587df9cf.js"><link rel="prefetch" href="/doc/assets/index.html.cffff73c.js"><link rel="prefetch" href="/doc/assets/index.html.0faea7db.js"><link rel="prefetch" href="/doc/assets/index.html.9ec36555.js"><link rel="prefetch" href="/doc/assets/index.html.4fbceb17.js"><link rel="prefetch" href="/doc/assets/index.html.a8892ad4.js"><link rel="prefetch" href="/doc/assets/index.html.1a7d6859.js"><link rel="prefetch" href="/doc/assets/index.html.5c08cce8.js"><link rel="prefetch" href="/doc/assets/index.html.ff1641e6.js"><link rel="prefetch" href="/doc/assets/index.html.10100559.js"><link rel="prefetch" href="/doc/assets/index.html.eca48ebd.js"><link rel="prefetch" href="/doc/assets/index.html.d9180794.js"><link rel="prefetch" href="/doc/assets/Spring.html.41ca96bd.js"><link rel="prefetch" href="/doc/assets/SpringBoot.html.c063ae1a.js"><link rel="prefetch" href="/doc/assets/SpringBoot源码.html.cdd45461.js"><link rel="prefetch" href="/doc/assets/SpringBoot高级.html.b3e5002b.js"><link rel="prefetch" href="/doc/assets/SpringMVC.html.25759dd3.js"><link rel="prefetch" href="/doc/assets/SpringSecurity.html.2ba8791d.js"><link rel="prefetch" href="/doc/assets/index.html.3afa53b5.js"><link rel="prefetch" href="/doc/assets/index.html.1963ae5c.js"><link rel="prefetch" href="/doc/assets/index.html.657aec84.js"><link rel="prefetch" href="/doc/assets/index.html.871b2105.js"><link rel="prefetch" href="/doc/assets/index.html.46266feb.js"><link rel="prefetch" href="/doc/assets/index.html.019ddb74.js"><link rel="prefetch" href="/doc/assets/index.html.2636a08e.js"><link rel="prefetch" href="/doc/assets/index.html.c6a50762.js"><link rel="prefetch" href="/doc/assets/index.html.6632d187.js"><link rel="prefetch" href="/doc/assets/index.html.480096df.js"><link rel="prefetch" href="/doc/assets/index.html.7bf9c484.js"><link rel="prefetch" href="/doc/assets/index.html.1ca63bf8.js"><link rel="prefetch" href="/doc/assets/index.html.ee1ff92b.js"><link rel="prefetch" href="/doc/assets/index.html.d1efbe95.js"><link rel="prefetch" href="/doc/assets/index.html.d302d742.js"><link rel="prefetch" href="/doc/assets/index.html.73b0a46e.js"><link rel="prefetch" href="/doc/assets/index.html.9b9e7b22.js"><link rel="prefetch" href="/doc/assets/index.html.5080b714.js"><link rel="prefetch" href="/doc/assets/index.html.5a365a3f.js"><link rel="prefetch" href="/doc/assets/index.html.ea186b24.js"><link rel="prefetch" href="/doc/assets/index.html.da1b811a.js"><link rel="prefetch" href="/doc/assets/index.html.ba20a9fa.js"><link rel="prefetch" href="/doc/assets/index.html.23e205db.js"><link rel="prefetch" href="/doc/assets/index.html.92cefa25.js"><link rel="prefetch" href="/doc/assets/index.html.0519d6c0.js"><link rel="prefetch" href="/doc/assets/index.html.df3e94ce.js"><link rel="prefetch" href="/doc/assets/index.html.850ddff2.js"><link rel="prefetch" href="/doc/assets/index.html.060bc27e.js"><link rel="prefetch" href="/doc/assets/index.html.e9e53a65.js"><link rel="prefetch" href="/doc/assets/index.html.e03489a4.js"><link rel="prefetch" href="/doc/assets/index.html.5730a56d.js"><link rel="prefetch" href="/doc/assets/index.html.b2f4abe8.js"><link rel="prefetch" href="/doc/assets/index.html.cafd859a.js"><link rel="prefetch" href="/doc/assets/index.html.c8328127.js"><link rel="prefetch" href="/doc/assets/index.html.887c0664.js"><link rel="prefetch" href="/doc/assets/index.html.4bf77624.js"><link rel="prefetch" href="/doc/assets/index.html.0e7972f9.js"><link rel="prefetch" href="/doc/assets/index.html.265aab2e.js"><link rel="prefetch" href="/doc/assets/index.html.ec74946d.js"><link rel="prefetch" href="/doc/assets/index.html.e3a2fec1.js"><link rel="prefetch" href="/doc/assets/index.html.36b699b6.js"><link rel="prefetch" href="/doc/assets/index.html.fdaf1cae.js"><link rel="prefetch" href="/doc/assets/index.html.ae3b119d.js"><link rel="prefetch" href="/doc/assets/index.html.b6c53f53.js"><link rel="prefetch" href="/doc/assets/index.html.0773f88d.js"><link rel="prefetch" href="/doc/assets/index.html.d571ef54.js"><link rel="prefetch" href="/doc/assets/index.html.86f9e908.js"><link rel="prefetch" href="/doc/assets/index.html.60f723ac.js"><link rel="prefetch" href="/doc/assets/index.html.01581c9b.js"><link rel="prefetch" href="/doc/assets/index.html.d96d738e.js"><link rel="prefetch" href="/doc/assets/index.html.5ddae78d.js"><link rel="prefetch" href="/doc/assets/index.html.7c0814ab.js"><link rel="prefetch" href="/doc/assets/index.html.965b7fff.js"><link rel="prefetch" href="/doc/assets/vue3快速上手.html.8773c5ea.js"><link rel="prefetch" href="/doc/assets/index.html.b2090b45.js"><link rel="prefetch" href="/doc/assets/index.html.f6fbe2a7.js"><link rel="prefetch" href="/doc/assets/index.html.5079d83e.js"><link rel="prefetch" href="/doc/assets/index.html.0e7d3814.js"><link rel="prefetch" href="/doc/assets/index.html.236535af.js"><link rel="prefetch" href="/doc/assets/index.html.e7057fa7.js"><link rel="prefetch" href="/doc/assets/index.html.0dfecf7e.js"><link rel="prefetch" href="/doc/assets/index.html.ba833381.js"><link rel="prefetch" href="/doc/assets/404.html.93146c89.js"><link rel="prefetch" href="/doc/assets/index.html.3b7265f0.js"><link rel="prefetch" href="/doc/assets/index.html.f94b83e6.js"><link rel="prefetch" href="/doc/assets/index.html.478d12bf.js"><link rel="prefetch" href="/doc/assets/index.html.9eee768a.js"><link rel="prefetch" href="/doc/assets/index.html.2b8b2ed7.js"><link rel="prefetch" href="/doc/assets/index.html.a370c4da.js"><link rel="prefetch" href="/doc/assets/index.html.4078504f.js"><link rel="prefetch" href="/doc/assets/index.html.0a470d26.js"><link rel="prefetch" href="/doc/assets/index.html.70589c68.js"><link rel="prefetch" href="/doc/assets/index.html.3e00e696.js"><link rel="prefetch" href="/doc/assets/index.html.a2857e37.js"><link rel="prefetch" href="/doc/assets/index.html.11a24d88.js"><link rel="prefetch" href="/doc/assets/index.html.13fcd6dc.js"><link rel="prefetch" href="/doc/assets/index.html.bb926e52.js"><link rel="prefetch" href="/doc/assets/index.html.83c356d4.js"><link rel="prefetch" href="/doc/assets/index.html.9093f441.js"><link rel="prefetch" href="/doc/assets/index.html.99329590.js"><link rel="prefetch" href="/doc/assets/index.html.a25f2824.js"><link rel="prefetch" href="/doc/assets/index.html.5dd4e8e8.js"><link rel="prefetch" href="/doc/assets/index.html.80a1a8a8.js"><link rel="prefetch" href="/doc/assets/index.html.e6aaf5e4.js"><link rel="prefetch" href="/doc/assets/index.html.4b4f53af.js"><link rel="prefetch" href="/doc/assets/index.html.63d82858.js"><link rel="prefetch" href="/doc/assets/index.html.02f66c42.js"><link rel="prefetch" href="/doc/assets/index.html.b02e0cb9.js"><link rel="prefetch" href="/doc/assets/index.html.b2cf2462.js"><link rel="prefetch" href="/doc/assets/index.html.4d88523a.js"><link rel="prefetch" href="/doc/assets/index.html.b6d3a8c2.js"><link rel="prefetch" href="/doc/assets/index.html.8e3bc1fc.js"><link rel="prefetch" href="/doc/assets/index.html.593a1904.js"><link rel="prefetch" href="/doc/assets/index.html.d0fdf009.js"><link rel="prefetch" href="/doc/assets/index.html.bb125db3.js"><link rel="prefetch" href="/doc/assets/index.html.7a967c9a.js"><link rel="prefetch" href="/doc/assets/index.html.ca6b22e1.js"><link rel="prefetch" href="/doc/assets/index.html.e1c469a1.js"><link rel="prefetch" href="/doc/assets/index.html.ff09b3af.js"><link rel="prefetch" href="/doc/assets/index.html.ec4bbb87.js"><link rel="prefetch" href="/doc/assets/index.html.12c1e355.js"><link rel="prefetch" href="/doc/assets/index.html.8a4045e6.js"><link rel="prefetch" href="/doc/assets/index.html.b54dc8a6.js"><link rel="prefetch" href="/doc/assets/index.html.721d96fd.js"><link rel="prefetch" href="/doc/assets/index.html.d855e8ed.js"><link rel="prefetch" href="/doc/assets/index.html.17fbd68b.js"><link rel="prefetch" href="/doc/assets/index.html.ad5ccf5a.js"><link rel="prefetch" href="/doc/assets/index.html.130dead3.js"><link rel="prefetch" href="/doc/assets/index.html.0bcc78cc.js"><link rel="prefetch" href="/doc/assets/index.html.557897f7.js"><link rel="prefetch" href="/doc/assets/index.html.1d57cd02.js"><link rel="prefetch" href="/doc/assets/index.html.df77ede5.js"><link rel="prefetch" href="/doc/assets/index.html.ac04a9ed.js"><link rel="prefetch" href="/doc/assets/index.html.037f3861.js"><link rel="prefetch" href="/doc/assets/index.html.08a635f2.js"><link rel="prefetch" href="/doc/assets/index.html.d37ad707.js"><link rel="prefetch" href="/doc/assets/index.html.af40cb25.js"><link rel="prefetch" href="/doc/assets/index.html.7b09b414.js"><link rel="prefetch" href="/doc/assets/index.html.ca416dcc.js"><link rel="prefetch" href="/doc/assets/index.html.f5eae5e4.js"><link rel="prefetch" href="/doc/assets/index.html.acf5622e.js"><link rel="prefetch" href="/doc/assets/index.html.77c30969.js"><link rel="prefetch" href="/doc/assets/index.html.ff8fef88.js"><link rel="prefetch" href="/doc/assets/index.html.b03ad9ee.js"><link rel="prefetch" href="/doc/assets/index.html.883bb815.js"><link rel="prefetch" href="/doc/assets/index.html.e5048f53.js"><link rel="prefetch" href="/doc/assets/index.html.80bf8279.js"><link rel="prefetch" href="/doc/assets/index.html.411d2f13.js"><link rel="prefetch" href="/doc/assets/index.html.e55b3889.js"><link rel="prefetch" href="/doc/assets/Spring.html.2f3df8d9.js"><link rel="prefetch" href="/doc/assets/SpringBoot.html.9cb899e2.js"><link rel="prefetch" href="/doc/assets/SpringBoot源码.html.6dd51782.js"><link rel="prefetch" href="/doc/assets/SpringBoot高级.html.74275d08.js"><link rel="prefetch" href="/doc/assets/SpringMVC.html.cf650f7b.js"><link rel="prefetch" href="/doc/assets/SpringSecurity.html.1e2f9882.js"><link rel="prefetch" href="/doc/assets/index.html.8489e95c.js"><link rel="prefetch" href="/doc/assets/index.html.4fc255fb.js"><link rel="prefetch" href="/doc/assets/index.html.6e298d1f.js"><link rel="prefetch" href="/doc/assets/index.html.dfb5c354.js"><link rel="prefetch" href="/doc/assets/index.html.55c13f7d.js"><link rel="prefetch" href="/doc/assets/index.html.9746da44.js"><link rel="prefetch" href="/doc/assets/index.html.5cad0d30.js"><link rel="prefetch" href="/doc/assets/index.html.a5a742fd.js"><link rel="prefetch" href="/doc/assets/index.html.2d7d46f5.js"><link rel="prefetch" href="/doc/assets/index.html.4fd15fc0.js"><link rel="prefetch" href="/doc/assets/index.html.5cf91540.js"><link rel="prefetch" href="/doc/assets/index.html.3d50e978.js"><link rel="prefetch" href="/doc/assets/index.html.21ff9d3b.js"><link rel="prefetch" href="/doc/assets/index.html.47b83ec4.js"><link rel="prefetch" href="/doc/assets/index.html.bc304f81.js"><link rel="prefetch" href="/doc/assets/index.html.b2a59940.js"><link rel="prefetch" href="/doc/assets/index.html.13415a43.js"><link rel="prefetch" href="/doc/assets/index.html.100ec837.js"><link rel="prefetch" href="/doc/assets/index.html.33aece6b.js"><link rel="prefetch" href="/doc/assets/index.html.e61dd289.js"><link rel="prefetch" href="/doc/assets/index.html.64183ae2.js"><link rel="prefetch" href="/doc/assets/index.html.446a1818.js"><link rel="prefetch" href="/doc/assets/index.html.97ea4a5c.js"><link rel="prefetch" href="/doc/assets/index.html.a6ef03fb.js"><link rel="prefetch" href="/doc/assets/index.html.3920cc47.js"><link rel="prefetch" href="/doc/assets/index.html.34f4e287.js"><link rel="prefetch" href="/doc/assets/index.html.1351290b.js"><link rel="prefetch" href="/doc/assets/index.html.84a20a4f.js"><link rel="prefetch" href="/doc/assets/index.html.e55a3317.js"><link rel="prefetch" href="/doc/assets/index.html.a5eeaab0.js"><link rel="prefetch" href="/doc/assets/index.html.a8d854c3.js"><link rel="prefetch" href="/doc/assets/index.html.74d28158.js"><link rel="prefetch" href="/doc/assets/index.html.9b6544ca.js"><link rel="prefetch" href="/doc/assets/index.html.ea3deaa2.js"><link rel="prefetch" href="/doc/assets/index.html.f5114c18.js"><link rel="prefetch" href="/doc/assets/index.html.ca8dada1.js"><link rel="prefetch" href="/doc/assets/index.html.0d3a5370.js"><link rel="prefetch" href="/doc/assets/index.html.13e899ea.js"><link rel="prefetch" href="/doc/assets/index.html.4f4461aa.js"><link rel="prefetch" href="/doc/assets/index.html.b6ced39d.js"><link rel="prefetch" href="/doc/assets/index.html.6c0283f0.js"><link rel="prefetch" href="/doc/assets/index.html.01661ebc.js"><link rel="prefetch" href="/doc/assets/index.html.657c6ed2.js"><link rel="prefetch" href="/doc/assets/index.html.f5f7aed0.js"><link rel="prefetch" href="/doc/assets/index.html.cdd6e499.js"><link rel="prefetch" href="/doc/assets/index.html.2d661523.js"><link rel="prefetch" href="/doc/assets/index.html.6893b4fb.js"><link rel="prefetch" href="/doc/assets/index.html.566e406c.js"><link rel="prefetch" href="/doc/assets/index.html.1357e2d3.js"><link rel="prefetch" href="/doc/assets/index.html.d910030e.js"><link rel="prefetch" href="/doc/assets/index.html.4d5146a8.js"><link rel="prefetch" href="/doc/assets/index.html.d830c4f5.js"><link rel="prefetch" href="/doc/assets/index.html.b1bef10b.js"><link rel="prefetch" href="/doc/assets/vue3快速上手.html.d36d3c30.js"><link rel="prefetch" href="/doc/assets/index.html.1e6ab806.js"><link rel="prefetch" href="/doc/assets/index.html.4125d933.js"><link rel="prefetch" href="/doc/assets/index.html.c5dc4567.js"><link rel="prefetch" href="/doc/assets/index.html.451edb2d.js"><link rel="prefetch" href="/doc/assets/index.html.a665dde3.js"><link rel="prefetch" href="/doc/assets/index.html.5ba5e8a1.js"><link rel="prefetch" href="/doc/assets/index.html.23b6b000.js"><link rel="prefetch" href="/doc/assets/index.html.629d6531.js"><link rel="prefetch" href="/doc/assets/404.html.d315880d.js"><link rel="prefetch" href="/doc/assets/404.bebaa092.js"><link rel="prefetch" href="/doc/assets/Layout.4134e473.js">
    <link rel="stylesheet" href="/doc/assets/style.83db67df.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/doc/" class=""><img class="logo" src="https://cdn-statics.zmn.cn/_nuxt/img/logo_web.b793f2a.png" alt="zmn.cn"><span class="site-name can-hide">zmn.cn</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><a href="/doc/" class="" aria-label="首页"><!--[--><!--]--> 首页 <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Java"><span class="title">Java</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Java"><span class="title">Java</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/doc/java/kafka/" class="" aria-label="Kafka"><!--[--><!--]--> Kafka <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/redis/" class="" aria-label="Redis"><!--[--><!--]--> Redis <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/skywalking/" class="" aria-label="SkyWalking"><!--[--><!--]--> SkyWalking <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/es/01/" class="" aria-label="ElasticSearch"><!--[--><!--]--> ElasticSearch <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/drools/" class="" aria-label="Drools"><!--[--><!--]--> Drools <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/jvm/01/" class="" aria-label="JVM"><!--[--><!--]--> JVM <!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="BigData"><span class="title">BigData</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="BigData"><span class="title">BigData</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/doc/bigdata/hadoop/core/hadoop/01/" class="" aria-label="Hadoop"><!--[--><!--]--> Hadoop <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/bigdata/scala/01base/" class="" aria-label="Scala"><!--[--><!--]--> Scala <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/bigdata/spark/core/base/" class="" aria-label="Spark"><!--[--><!--]--> Spark <!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><a class="external-link" href="https://github.com/faustine8/doc" rel="noopener noreferrer" target="_blank" aria-label="GitHub"><!--[--><!--]--> GitHub <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><button class="toggle-dark-button" title="toggle dark mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><form class="search-box" role="search"><input type="search" placeholder="搜索" autocomplete="off" spellcheck="false" value><!----></form></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><a href="/doc/" class="" aria-label="首页"><!--[--><!--]--> 首页 <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="Java"><span class="title">Java</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="Java"><span class="title">Java</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/doc/java/kafka/" class="" aria-label="Kafka"><!--[--><!--]--> Kafka <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/redis/" class="" aria-label="Redis"><!--[--><!--]--> Redis <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/skywalking/" class="" aria-label="SkyWalking"><!--[--><!--]--> SkyWalking <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/es/01/" class="" aria-label="ElasticSearch"><!--[--><!--]--> ElasticSearch <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/drools/" class="" aria-label="Drools"><!--[--><!--]--> Drools <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/java/jvm/01/" class="" aria-label="JVM"><!--[--><!--]--> JVM <!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="BigData"><span class="title">BigData</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="BigData"><span class="title">BigData</span><span class="right arrow"></span></button><!--[--><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/doc/bigdata/hadoop/core/hadoop/01/" class="" aria-label="Hadoop"><!--[--><!--]--> Hadoop <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/bigdata/scala/01base/" class="" aria-label="Scala"><!--[--><!--]--> Scala <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/doc/bigdata/spark/core/base/" class="" aria-label="Spark"><!--[--><!--]--> Spark <!--[--><!--]--></a></li><!--]--></ul><!--]--></div></div><div class="navbar-item"><a class="external-link" href="https://github.com/faustine8/doc" rel="noopener noreferrer" target="_blank" aria-label="GitHub"><!--[--><!--]--> GitHub <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading">5. HDFS分布式文件系统 <!----></p><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-1-hdfs-简介" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.1 HDFS 简介"><!--[--><!--]--> 5.1 HDFS 简介 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-2-hdfs-的重要概念【重点掌握】" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2 HDFS 的重要概念【重点掌握】"><!--[--><!--]--> 5.2 HDFS 的重要概念【重点掌握】 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-2-1-典型的-master-slave-架构" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2.1 典型的 Master/Slave 架构"><!--[--><!--]--> 5.2.1 典型的 Master/Slave 架构 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-2-2-分块存储-block机制" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2.2 分块存储(block机制)"><!--[--><!--]--> 5.2.2 分块存储(block机制) <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-2-3-命名空间-namespace" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2.3 命名空间(NameSpace)"><!--[--><!--]--> 5.2.3 命名空间(NameSpace) <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-2-4-namenode元数据管理" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2.4 NameNode元数据管理"><!--[--><!--]--> 5.2.4 NameNode元数据管理 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-2-5-datanode数据存储" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2.5 DataNode数据存储"><!--[--><!--]--> 5.2.5 DataNode数据存储 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-2-6-副本机制" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2.6 副本机制"><!--[--><!--]--> 5.2.6 副本机制 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-2-7-一次写入-多次读出" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.2.7 一次写入，多次读出"><!--[--><!--]--> 5.2.7 一次写入，多次读出 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-3-hdfs-架构【重点掌握】" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.3 HDFS 架构【重点掌握】"><!--[--><!--]--> 5.3 HDFS 架构【重点掌握】 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-3-1-namenode-nn" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.3.1 NameNode(nn)"><!--[--><!--]--> 5.3.1 NameNode(nn) <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-3-2-datanode" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.3.2 DataNode"><!--[--><!--]--> 5.3.2 DataNode <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-3-3-client" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.3.3 Client"><!--[--><!--]--> 5.3.3 Client <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-4-hdfs-客户端操作" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.4 HDFS 客户端操作"><!--[--><!--]--> 5.4 HDFS 客户端操作 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-4-1-shell-命令行操作-hdfs" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.4.1 Shell 命令行操作 HDFS"><!--[--><!--]--> 5.4.1 Shell 命令行操作 HDFS <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-4-2-java客户端" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.4.2 JAVA客户端"><!--[--><!--]--> 5.4.2 JAVA客户端 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-5-hdfs-读写解析" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.5 HDFS 读写解析"><!--[--><!--]--> 5.5 HDFS 读写解析 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-5-1-hdfs-读数据流程" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.5.1 HDFS 读数据流程"><!--[--><!--]--> 5.5.1 HDFS 读数据流程 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-5-2-hdfs-写数据流程" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.5.2 HDFS 写数据流程"><!--[--><!--]--> 5.5.2 HDFS 写数据流程 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-5-3-packet-验证" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.5.3 packet 验证"><!--[--><!--]--> 5.5.3 packet 验证 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-6-nn与2nn" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.6 NN与2NN"><!--[--><!--]--> 5.6 NN与2NN <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-6-1-hdfs-元数据管理机制" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.6.1 HDFS 元数据管理机制"><!--[--><!--]--> 5.6.1 HDFS 元数据管理机制 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-6-2-fsimage-与-edits-文件解析" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.6.2 fsimage 与 edits 文件解析"><!--[--><!--]--> 5.6.2 fsimage 与 edits 文件解析 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-6-3-checkpoint-周期" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.6.3 checkpoint 周期"><!--[--><!--]--> 5.6.3 checkpoint 周期 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-7-nn故障处理" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.7 NN故障处理"><!--[--><!--]--> 5.7 NN故障处理 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-8-限额与归档及集群安全模式" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.8 限额与归档及集群安全模式"><!--[--><!--]--> 5.8 限额与归档及集群安全模式 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-8-1-hdfs文件限额配置" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.8.1 HDFS文件限额配置"><!--[--><!--]--> 5.8.1 HDFS文件限额配置 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-8-2-hdfs的安全模式" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.8.2 HDFS的安全模式"><!--[--><!--]--> 5.8.2 HDFS的安全模式 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-8-3-hadoop归档技术" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.8.3 Hadoop归档技术"><!--[--><!--]--> 5.8.3 Hadoop归档技术 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-9-日志采集综合案例" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.9 日志采集综合案例"><!--[--><!--]--> 5.9 日志采集综合案例 <!--[--><!--]--></a><!--[--><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-9-1-需求分析" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.9.1 需求分析"><!--[--><!--]--> 5.9.1 需求分析 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-9-2-代码实现" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.9.2 代码实现"><!--[--><!--]--> 5.9.2 代码实现 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/doc/bigdata/hadoop/core/hdfs/#_5-9-3-代码优化" class="router-link-active router-link-exact-active sidebar-item" aria-label="5.9.3 代码优化"><!--[--><!--]--> 5.9.3 代码优化 <!--[--><!--]--></a><!----></li><!--]--></ul><!--]--></li><!--]--></ul><!--]--></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><h1 id="_5-hdfs分布式文件系统" tabindex="-1"><a class="header-anchor" href="#_5-hdfs分布式文件系统" aria-hidden="true">#</a> 5. HDFS分布式文件系统</h1><h2 id="_5-1-hdfs-简介" tabindex="-1"><a class="header-anchor" href="#_5-1-hdfs-简介" aria-hidden="true">#</a> 5.1 HDFS 简介</h2><p>HDFS (全称:Hadoop Distribute File System，Hadoop 分布式文件系统) 是 Hadoop 核心组成，是分布式存储服务。</p><p>分布式文件系统横跨多台计算机，在大数据时代有着广泛的应用前景，它们为存储和处理超大规模数据提供所需的扩展能力。</p><p>HDFS是分布式文件系统中的一种。</p><h2 id="_5-2-hdfs-的重要概念【重点掌握】" tabindex="-1"><a class="header-anchor" href="#_5-2-hdfs-的重要概念【重点掌握】" aria-hidden="true">#</a> 5.2 HDFS 的重要概念【重点掌握】</h2><p>HDFS 通过统一的命名空间目录树来定位文件; 另外，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色(分布式本质是拆分，各司其职);</p><h3 id="_5-2-1-典型的-master-slave-架构" tabindex="-1"><a class="header-anchor" href="#_5-2-1-典型的-master-slave-架构" aria-hidden="true">#</a> 5.2.1 典型的 Master/Slave 架构</h3><p>HDFS 的架构是典型的 Master/Slave 结构。</p><p>HDFS集群往往是一个NameNode(HA架构会有两个NameNode,联邦机制)+多个DataNode组成;</p><p>NameNode是集群的主节点，DataNode是集群的从节点。</p><h3 id="_5-2-2-分块存储-block机制" tabindex="-1"><a class="header-anchor" href="#_5-2-2-分块存储-block机制" aria-hidden="true">#</a> 5.2.2 分块存储(block机制)</h3><p>HDFS 中的文件在物理上是分块存储(block)的，块的大小可以通过配置参数来规定;</p><p>Hadoop2.x版本中默认的block大小是128M;</p><h3 id="_5-2-3-命名空间-namespace" tabindex="-1"><a class="header-anchor" href="#_5-2-3-命名空间-namespace" aria-hidden="true">#</a> 5.2.3 命名空间(NameSpace)</h3><p>HDFS 支持传统的层次型文件组织结构。用户或者应用程序可以创建目录，然后将文件保存在这些目录里。文件系统命名空间的层次结构和大多数现有的文件系统类似: 用户可以创建、删除、移动或重命名文件。</p><p>NameNode 负责维护文件系统的命名空间，任何对文件系统命名空间或属性的修改都将被 NameNode 记录下来。</p><p>HDFS提供给客户端一个抽象目录树，访问形式: <code>hdfs://namenode的hostname:port/test/input</code>。</p><p>如：<a href="hdfs://linux121:9000/test/input">hdfs://linux121:9000/test/input</a></p><h3 id="_5-2-4-namenode元数据管理" tabindex="-1"><a class="header-anchor" href="#_5-2-4-namenode元数据管理" aria-hidden="true">#</a> 5.2.4 NameNode元数据管理</h3><p>我们把目录结构及文件分块位置信息叫做元数据。</p><p>NameNode的元数据记录每一个文件所对应的block信息(block的id,以及所在的DataNode节点的信息)</p><h3 id="_5-2-5-datanode数据存储" tabindex="-1"><a class="header-anchor" href="#_5-2-5-datanode数据存储" aria-hidden="true">#</a> 5.2.5 DataNode数据存储</h3><p>文件的各个 block 的具体存储管理由 DataNode 节点承担。</p><p>一个block会有多个DataNode来存储，DataNode 会定时向 NameNode 来汇报自己持有的block信息。</p><h3 id="_5-2-6-副本机制" tabindex="-1"><a class="header-anchor" href="#_5-2-6-副本机制" aria-hidden="true">#</a> 5.2.6 副本机制</h3><p>为了容错，文件的所有 block 都会有副本。每个文件的 block 大小和副本系数都是可配置的。</p><p>应用程序可以指定某个文件的副本数目。副本系数可以在文件创建的时候指定，也可以在之后改变。 副本数量默认是3个。</p><h3 id="_5-2-7-一次写入-多次读出" tabindex="-1"><a class="header-anchor" href="#_5-2-7-一次写入-多次读出" aria-hidden="true">#</a> 5.2.7 一次写入，多次读出</h3><p>HDFS 是设计成适应一次写入，多次读出的场景，且不支持文件的随机修改。(支持追加写入，不只支持随机更新)</p><p>正因为如此，HDFS 适合用来做大数据分析的底层存储服务，并不适合用来做网盘等应用(修改不方便，延迟大，网络开销大，成本太高)</p><h2 id="_5-3-hdfs-架构【重点掌握】" tabindex="-1"><a class="header-anchor" href="#_5-3-hdfs-架构【重点掌握】" aria-hidden="true">#</a> 5.3 HDFS 架构【重点掌握】</h2><p><img src="/doc/assets/README-1639886528176.b8e79650.png" alt="HDFS组成架构图"></p><h3 id="_5-3-1-namenode-nn" tabindex="-1"><a class="header-anchor" href="#_5-3-1-namenode-nn" aria-hidden="true">#</a> 5.3.1 NameNode(nn)</h3><p>HDFS 集群的管理者，Master</p><ul><li>维护管理Hdfs的名称空间(NameSpace)</li><li>维护副本策略</li><li>记录文件块(Block)的映射信息</li><li>负责处理客户端读写请求</li></ul><h3 id="_5-3-2-datanode" tabindex="-1"><a class="header-anchor" href="#_5-3-2-datanode" aria-hidden="true">#</a> 5.3.2 DataNode</h3><p>NameNode 下达命令，DataNode 执行实际操作，Slave 节点。</p><ul><li>保存实际的数据块</li><li>负责数据块的读写</li></ul><h3 id="_5-3-3-client" tabindex="-1"><a class="header-anchor" href="#_5-3-3-client" aria-hidden="true">#</a> 5.3.3 Client</h3><p>客户端</p><ul><li>上传文件到 HDFS 的时候，Client 负责将文件切分成 Block, 然后进行上传</li><li>与 NameNode 交互，获取文件的位置信息</li><li>与 DataNode 交互，读取或写入文件</li><li>Client 可以使用一些命令来管理HDFS或者访问HDFS</li></ul><h2 id="_5-4-hdfs-客户端操作" tabindex="-1"><a class="header-anchor" href="#_5-4-hdfs-客户端操作" aria-hidden="true">#</a> 5.4 HDFS 客户端操作</h2><h3 id="_5-4-1-shell-命令行操作-hdfs" tabindex="-1"><a class="header-anchor" href="#_5-4-1-shell-命令行操作-hdfs" aria-hidden="true">#</a> 5.4.1 Shell 命令行操作 HDFS</h3><ol><li>基本语法</li></ol><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>bin/hadoop fs 具体命令
bin/hdfs dfs 具体命令
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ol start="2"><li>HDFS 命令演示</li></ol><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 1.启动Hadoop集群(方便后续的测试)</span>
sbin/start-dfs.sh
sbin/start-yarn.sh

<span class="token comment"># 2. -help:输出这个命令参数</span>
hadoop fs -help <span class="token function">rm</span>

<span class="token comment"># 3. -ls: 显示目录信息</span>
hadoop fs -ls /

<span class="token comment"># 4. -mkdir:在HDFS上创建目录</span>
hadoop fs -mkdir -p /zmn/bigdata

<span class="token comment"># 5. -moveFromLocal:从本地剪切粘贴到HDFS</span>
<span class="token function">touch</span> hadoop.txt
hadoop fs -moveFromLocal ./hadoop.txt /zmn/bigdata

<span class="token comment"># 6. -appendToFile:追加一个文件到已经存在的文件末尾</span>
<span class="token function">touch</span> hdfs.txt
<span class="token function">vi</span> hdfs.txt
<span class="token comment"># 输入如下内容</span>
<span class="token comment"># namenode datanode block replication</span>
hadoop fs -appendToFile ./hdfs.txt /zmn/bigdata/hadoop.txt

<span class="token comment"># 7. -cat:显示文件内容</span>
hadoop fs -cat /zmn/bigdata/hadoop.txt

<span class="token comment">#8. -chgrp 、-chmod、-chown:Linux文件系统中的用法一样，修改文件所属权限</span>
hadoop fs  -chmod  <span class="token number">666</span>  /zmn/bigdata/hadoop.txt
hadoop fs -chown root:root /zmn/bigdata/hadoop.txt

<span class="token comment">#9. -copyFromLocal:从本地文件系统中拷贝文件到HDFS路径去</span>
hadoop fs -copyFromLocal README.txt /

<span class="token comment">#10. -copyToLocal:从HDFS拷贝到本地</span>
hadoop fs -copyToLocal /zmn/bigdata/hadoop.txt ./

<span class="token comment">#11. -cp :从HDFS的一个路径拷贝到HDFS的另一个路径</span>
hadoop fs -cp /zmn/bigdata/hadoop.txt /hdfs.txt

<span class="token comment"># 12. -mv:在HDFS目录中移动文件</span>
hadoop fs -mv /hdfs.txt /zmn/bigdata/

<span class="token comment"># 13. -get:等同于copyToLocal，就是从HDFS下载文件到本地</span>
hadoop fs -get /zmn/bigdata/hadoop.txt ./

<span class="token comment"># 14. -put:等同于 copyFromLocal</span>
hadoop fs -mkdir -p /user/root/test/
<span class="token comment"># #本地文件系统创建yarn.txt</span>
<span class="token function">vim</span> yarn.txt
<span class="token comment"># 写入如下内容</span>
<span class="token comment"># resourcemanager nodemanager</span>
hadoop fs -put ./yarn.txt /user/root/test/

<span class="token comment"># 15. -tail:显示一个文件的末尾</span>
hadoop fs -tail /user/root/test/yarn.txt

<span class="token comment"># 16. -rm:删除文件或文件夹</span>
hadoop fs -rm /user/root/test/yarn.txt

<span class="token comment"># 17. -rmdir:删除空目录</span>
hadoop fs -mkdir /test
hadoop fs -rmdir /test

<span class="token comment"># 18. -du:统计文件夹的大小信息</span>
<span class="token comment"># 整个文件夹大小</span>
hadoop fs -du -s -h /user/root/test
<span class="token comment"># 具体到文件</span>
hadoop fs -du  -h /user/root/test

<span class="token comment"># 19. -setrep:设置HDFS中文件的副本数量</span>
hadoop fs -setrep <span class="token number">10</span> /zmn/bigdata/hadoop.txt

<span class="token comment"># 注意：这里设置的副本数只是记录在NameNode的元数据中，是否真的会有这么多副本，还得看DataNode的数量。</span>
<span class="token comment"># 因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br></div></div><h3 id="_5-4-2-java客户端" tabindex="-1"><a class="header-anchor" href="#_5-4-2-java客户端" aria-hidden="true">#</a> 5.4.2 JAVA客户端</h3><h4 id="_5-4-2-1-客户端环境准备" tabindex="-1"><a class="header-anchor" href="#_5-4-2-1-客户端环境准备" aria-hidden="true">#</a> 5.4.2.1 客户端环境准备</h4><ol><li>将 Hadoop-2.9.2 安装包解压到非中文路径(例如: <code>/opt/hadoop-2.9.2</code>)。</li><li>配置HADOOP_HOME环境变量</li><li>创建一个Maven工程ClientDemo</li><li>导入相应的依赖坐标+日志配置文件</li></ol><div class="language-xml ext-xml line-numbers-mode"><pre class="language-xml"><code><span class="token comment">&lt;!--  Hadoop-common, Hadoop-client, Hadoop-hdfs  --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-common<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.9.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.9.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-hdfs --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-hdfs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.9.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>test<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!--    测试和日志    --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>RELEASE<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>log4j-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.8.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br></div></div><p>为了便于控制程序运行打印的日志数量，添加日志配置文件: <code>log4j.properties</code>，文件内容:</p><div class="language-properties ext-properties line-numbers-mode"><pre class="language-properties"><code><span class="token key attr-name">log4j.rootLogger</span><span class="token punctuation">=</span><span class="token value attr-value">INFO, stdout</span>
<span class="token key attr-name">log4j.appender.stdout</span><span class="token punctuation">=</span><span class="token value attr-value">org.apache.log4j.ConsoleAppender</span>
<span class="token key attr-name">log4j.appender.stdout.layout</span><span class="token punctuation">=</span><span class="token value attr-value">org.apache.log4j.PatternLayout</span>
<span class="token key attr-name">log4j.appender.stdout.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token value attr-value">%d %p [%c] - %m%n</span>
<span class="token key attr-name">log4j.appender.logfile</span><span class="token punctuation">=</span><span class="token value attr-value">org.apache.log4j.FileAppender</span>
<span class="token key attr-name">log4j.appender.logfile.File</span><span class="token punctuation">=</span><span class="token value attr-value">target/spring.log</span>
<span class="token key attr-name">log4j.appender.logfile.layout</span><span class="token punctuation">=</span><span class="token value attr-value">org.apache.log4j.PatternLayout</span>
<span class="token key attr-name">log4j.appender.logfile.layout.ConversionPattern</span><span class="token punctuation">=</span><span class="token value attr-value">%d %p [%c] - %m%n</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ol start="5"><li><code>com.zmn.hdfs</code> 包下创建 <code>HdfsClient</code> 类</li></ol><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testMkDirs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">URISyntaxException</span><span class="token punctuation">,</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1.获取Hadoop集群的 Configuration 对象</span>
        <span class="token class-name">Configuration</span> configuration <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2.根据 Configuration 获取 FileSystem 对象</span>
        <span class="token class-name">FileSystem</span> fs <span class="token operator">=</span> <span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span><span class="token string">&quot;hdfs://linux121:9000&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> configuration<span class="token punctuation">,</span> <span class="token string">&quot;root&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 也可以通过这种方式获取 FileSystem</span>
        <span class="token comment">// configuration.set(&quot;fs.defaultFS&quot;, &quot;hdfs://linux121:9000&quot;);</span>
        <span class="token comment">// FileSystem fs = FileSystem.get(configuration);</span>

        <span class="token comment">// 3.使用 FileSystem 对象创建测试目录</span>
        fs<span class="token punctuation">.</span><span class="token function">mkdirs</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/api_test&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4.释放 FileSystem 对象(类似数据库连接)</span>
        fs<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>如果不指定操作HDFS集群的用户信息，默认是获取当前操作系统的用户信息，出现权限被拒绝的问题，报错如下:</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>org.apache.hadoop.security.AccessControlException: Permission denied: user=faustine, access=WRITE, inode=&quot;/&quot;:root:supergroup:drwxr-xr-x
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><h5 id="文件权限问题" tabindex="-1"><a class="header-anchor" href="#文件权限问题" aria-hidden="true">#</a> 文件权限问题</h5><p>HDFS的文件权限机制与Linux系统的文件权限机制类似!!</p><p><code>r:read w:write x:execute</code> 权限对于文件表示忽略，对于文件夹表示是否有权限访问其内容</p><p>如果Linux系统用户A使用 <code>hadoop</code> 命令创建一个文件，那么这个文件在 HDFS 当中的 owner 就是 A</p><p>HDFS文件权限的目的，防止好人做错事，而不是阻止坏人做坏事。HDFS相信你告诉我你是谁，你就是谁!!</p><ul><li>解决方案</li></ul><ol><li>每次获取获取FileSystem对象都指定用户信息</li><li>关闭HDFS集群权限校验</li></ol><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token function">vim</span> hdfs-site.xml <span class="token comment">#添加如下属性</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><div class="language-xml ext-xml line-numbers-mode"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.permissions<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><blockquote><p>修改完成之后要分发到其它节点，同时要重启HDFS集群。</p></blockquote><ol start="3"><li>基于HDFS权限本身比较鸡肋的特点，我们可以彻底放弃HDFS的权限校验</li></ol><p>如果生产环境中 我们可以考虑借助 kerberos 以及 sentry 等安全框架来管理大数据集群安全。所以我们直接修改 HDFS 的根目录权限为 777。</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>hadoop fs -chmod -R <span class="token number">777</span> /
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><h4 id="_5-4-2-2-hdfs-的-api-操作" tabindex="-1"><a class="header-anchor" href="#_5-4-2-2-hdfs-的-api-操作" aria-hidden="true">#</a> 5.4.2.2 HDFS 的 API 操作</h4><h5 id="_1-上传文件" tabindex="-1"><a class="header-anchor" href="#_1-上传文件" aria-hidden="true">#</a> 1.上传文件</h5><p>测试案例</p><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// 上传文件</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyFromLocalToHdfs</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 上传文件</span>
        <span class="token comment">// src:源文件目录；dst:目标文件路径(HDFS路径)</span>
        fs<span class="token punctuation">.</span><span class="token function">copyFromLocalFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/Users/faustine/Downloads/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>上传文件到 HDFS 默认为 3。如何改变上传文件的副本数量 ?</p><ol><li>可以在 configuration 中指定新的副本数量 <code>configuration.set(&quot;dfs.replication&quot;, &quot;2&quot;);</code></li><li>将hdfs-site.xml拷贝到项目的根目录下(<code>main/resoureces/</code>目录下)</li></ol><div class="language-xml ext-xml line-numbers-mode"><pre class="language-xml"><code><span class="token prolog">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class="token prolog">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!--副本数量 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><blockquote><p>在 <code>hadoop-hdfs</code> 的 jar 包中也可以发现项目根目录下 <code>hdfs-default.xml</code> 配置文件中有相关的配置，默认副本数为 3。</p></blockquote><ol start="3"><li>参数优先级</li></ol><p>参数优先级排序: 代码中设置的值 &gt; 用户自定义配置文件 &gt; 服务器的默认配置</p><h5 id="_2-下载文件" tabindex="-1"><a class="header-anchor" href="#_2-下载文件" aria-hidden="true">#</a> 2.下载文件</h5><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// 下载文件</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testCopyFromHdfsToLocal</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        <span class="token comment">// boolean: 是否删除源文件; src: hdfs路径；dst: 目标路径（本地路径）</span>
        fs<span class="token punctuation">.</span><span class="token function">copyToLocalFile</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/Users/faustine/Downloads/zmn_copy.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h5 id="_3-删除文件或文件夹" tabindex="-1"><a class="header-anchor" href="#_3-删除文件或文件夹" aria-hidden="true">#</a> 3.删除文件或文件夹</h5><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// 删除文件或文件夹</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testDeleteFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        fs<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/api_test2&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h5 id="_4-查看文件名称、权限、长度、块信息" tabindex="-1"><a class="header-anchor" href="#_4-查看文件名称、权限、长度、块信息" aria-hidden="true">#</a> 4.查看文件名称、权限、长度、块信息</h5><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// 遍历 HDFS 的根目录得到文件以及文件夹的信息：名称、权限、大小等.</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testListFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 得到一个迭代器：装有指定目录下所有文件信息</span>
        <span class="token class-name">RemoteIterator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LocatedFileStatus</span><span class="token punctuation">&gt;</span></span> remoteIterator <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listFiles</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 遍历迭代器</span>
        <span class="token keyword">while</span> <span class="token punctuation">(</span>remoteIterator<span class="token punctuation">.</span><span class="token function">hasNext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token class-name">LocatedFileStatus</span> fileStatus <span class="token operator">=</span> remoteIterator<span class="token punctuation">.</span><span class="token function">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 文件名</span>
            <span class="token class-name">String</span> fileName <span class="token operator">=</span> fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 长度（大小信息）</span>
            <span class="token keyword">long</span> len <span class="token operator">=</span> fileStatus<span class="token punctuation">.</span><span class="token function">getLen</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 权限</span>
            <span class="token class-name">FsPermission</span> permission <span class="token operator">=</span> fileStatus<span class="token punctuation">.</span><span class="token function">getPermission</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 分组</span>
            <span class="token class-name">String</span> group <span class="token operator">=</span> fileStatus<span class="token punctuation">.</span><span class="token function">getGroup</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 用户</span>
            <span class="token class-name">String</span> owner <span class="token operator">=</span> fileStatus<span class="token punctuation">.</span><span class="token function">getOwner</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 打印信息</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>fileName <span class="token operator">+</span> <span class="token string">&quot;\t&quot;</span> <span class="token operator">+</span> len <span class="token operator">+</span> <span class="token string">&quot;\t&quot;</span> <span class="token operator">+</span> permission <span class="token operator">+</span> <span class="token string">&quot;\t&quot;</span> <span class="token operator">+</span> group <span class="token operator">+</span> <span class="token string">&quot;\t&quot;</span> <span class="token operator">+</span> owner<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 块信息</span>
            <span class="token class-name">BlockLocation</span><span class="token punctuation">[</span><span class="token punctuation">]</span> blockLocations <span class="token operator">=</span> fileStatus<span class="token punctuation">.</span><span class="token function">getBlockLocations</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">BlockLocation</span> item <span class="token operator">:</span> blockLocations<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> hosts <span class="token operator">=</span> item<span class="token punctuation">.</span><span class="token function">getHosts</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> host <span class="token operator">:</span> hosts<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                    <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;主机名称：&quot;</span> <span class="token operator">+</span> host<span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;--------------------------&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br></div></div><h5 id="_5-文件夹判断" tabindex="-1"><a class="header-anchor" href="#_5-文件夹判断" aria-hidden="true">#</a> 5.文件夹判断</h5><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// 文件还是文件夹判断</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testIsFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        <span class="token class-name">FileStatus</span><span class="token punctuation">[</span><span class="token punctuation">]</span> fileStatuses <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listStatus</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">FileStatus</span> fileStatus <span class="token operator">:</span> fileStatuses<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">boolean</span> file <span class="token operator">=</span> fileStatus<span class="token punctuation">.</span><span class="token function">isFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>file<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;file:&quot;</span> <span class="token operator">+</span> fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
                <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;dir:&quot;</span> <span class="token operator">+</span> fileStatus<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><h5 id="_6-i-o流操作hdfs" tabindex="-1"><a class="header-anchor" href="#_6-i-o流操作hdfs" aria-hidden="true">#</a> 6 I/O流操作HDFS</h5><p>以上我们使用的API操作都是 HDFS 系统框架封装好的。我们自己也可以采用IO流的方式实现文件的上传和下载。</p><h6 id="_6-1-文件上传" tabindex="-1"><a class="header-anchor" href="#_6-1-文件上传" aria-hidden="true">#</a> 6.1 文件上传</h6><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// 使用IO流操作 HDFS</span>
<span class="token comment">// 上传文件：准备输入流读取本地文件，使用 HDFS 的输出流写出数据到 HDFS</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">uploadFileIO</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1.获取读取本地文件的输入流</span>
        <span class="token class-name">FileInputStream</span> inputStream <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">&quot;/Users/faustine/Downloads/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2.准备写数据到 HDFS</span>
        <span class="token class-name">FSDataOutputStream</span> fsDataOutputStream <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3.输入流数据拷贝到输出流</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>inputStream<span class="token punctuation">,</span> fsDataOutputStream<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4.可以再次关闭流(非必须)</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fsDataOutputStream<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>inputStream<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><h6 id="_6-2-文件下载" tabindex="-1"><a class="header-anchor" href="#_6-2-文件下载" aria-hidden="true">#</a> 6.2 文件下载</h6><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// 下载文件</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">downloadFileIO</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1.读取 HDFS 文件的输入流</span>
        <span class="token class-name">FSDataInputStream</span> in <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2.准备一个本地文件的输出流</span>
        <span class="token class-name">FileOutputStream</span> fileOutputStream <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">&quot;/Users/faustine/Downloads/zmn_copy.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3.流的拷贝</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> fileOutputStream<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4.关闭流(非必须)</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>fileOutputStream<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>in<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><h6 id="_6-3-seek-定位读取" tabindex="-1"><a class="header-anchor" href="#_6-3-seek-定位读取" aria-hidden="true">#</a> 6.3 seek 定位读取</h6><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// seek 定位读取 HDFS 指定文件</span>
    <span class="token comment">// 使用IO流读取文件，并把内容输出两次(本质就是读取文件内容输出两次)</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">seekReadFile</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1.创建一个读取 HDFS 文件的输入流</span>
        <span class="token class-name">FSDataInputStream</span> in <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2.控制台输出</span>
        <span class="token comment">// 3.实现流拷贝</span>
        <span class="token comment">// IOUtils.copyBytes(in, System.out, configuration);</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 不自动关闭流</span>
        <span class="token comment">// 4.再次读取文件</span>
        in<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// 定位从0偏移量(文件头部)再次读取</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 不自动关闭流</span>
        <span class="token comment">// 5.关闭输入流</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>in<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><h2 id="_5-5-hdfs-读写解析" tabindex="-1"><a class="header-anchor" href="#_5-5-hdfs-读写解析" aria-hidden="true">#</a> 5.5 HDFS 读写解析</h2><h3 id="_5-5-1-hdfs-读数据流程" tabindex="-1"><a class="header-anchor" href="#_5-5-1-hdfs-读数据流程" aria-hidden="true">#</a> 5.5.1 HDFS 读数据流程</h3><ol><li>客户端通过 Distributed FileSystem 向 NameNode 请求下载文件，NameNode 通过查询元数据，找到文件块所在的 DataNode 地址。</li></ol><blockquote><p>如果请求的文件被切分成了很多块，并不是一次性返回所有块的元数据信息，而是分批返回。等前一部分全部读取完成后，再返回下一部分块数据的元数据信息。</p></blockquote><ol start="2"><li>挑选一台 DataNode (就近原则，然后随机)服务器，请求读取数据。</li></ol><blockquote><p>网络距离远近</p></blockquote><ol start="3"><li>DataNode 开始传输数据给客户端(从磁盘里面读取数据输入流，以 Packet 为单位来做校验)。</li><li>客户端以 Packet 为单位接收，先在本地缓存，然后写入目标文件。</li></ol><h3 id="_5-5-2-hdfs-写数据流程" tabindex="-1"><a class="header-anchor" href="#_5-5-2-hdfs-写数据流程" aria-hidden="true">#</a> 5.5.2 HDFS 写数据流程</h3><ol><li>客户端通过 Distributed FileSystem 模块向 NameNode 请求上传文件，NameNode 检查目标文件是否已存在，父目录是否存在。</li><li>NameNode 返回是否可以上传。</li><li>客户端请求第一个 Block 上传到哪几个 DataNode 服务器上。</li><li>NameNode 返回3个 DataNode 节点，分别为dn1、dn2、dn3。</li><li>客户端通过 FSDataOutputStream 模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</li><li>dn1、dn2、dn3逐级应答客户端。</li><li>客户端开始往 dn1 上传第一个 Block(先从磁盘读取数据放到一个本地内存缓存)，以 Packet 为单位， dn1 收到一个Packet就会传给 dn2，dn2 传给 dn3; dn1 每传一个 packet 会放入一个确认队列等待确认。</li></ol><blockquote><p>也就是多副本，写入数据的时候就保证了各个节点的数据同步。</p></blockquote><ol start="8"><li>当一个 Block 传输完成之后，客户端再次请求 NameNode 上传第二个 Block 的服务器。(重复执行3-7步)。</li></ol><h3 id="_5-5-3-packet-验证" tabindex="-1"><a class="header-anchor" href="#_5-5-3-packet-验证" aria-hidden="true">#</a> 5.5.3 packet 验证</h3><p><code>fs.create()</code> 方法有一个重载实现的第二个参数是一个 <code>Progressable</code> 接口，他的 <code>progress</code> 方法就是每传输 64KB(packet) 就会执行一次。 (传输数据前的建立连接通道也会调用一次)</p><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">HdfsClientDemo</span> <span class="token punctuation">{</span>
    <span class="token comment">// 演示从本地文件系统上传文件到 HDFS 的过程</span>
    <span class="token annotation punctuation">@Test</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testUploadPacket</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
        <span class="token comment">// 1.准备读取本地文件的输入流</span>
        <span class="token class-name">FileInputStream</span> input <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">&quot;/Users/faustine/Downloads/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2.准备写出数据到 HDFS 的输出流</span>
        <span class="token class-name">FSDataOutputStream</span> out <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/zmn.txt&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-&gt;</span> <span class="token punctuation">{</span>
            <span class="token comment">// 这个 progress 方法就是每传输 64KB(packet) 就会执行一次。(传输数据前的建立连接通道也会调用一次)</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;&amp;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3.实现流拷贝</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>input<span class="token punctuation">,</span> out<span class="token punctuation">,</span> configuration<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4.关闭流</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">closeStream</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><h2 id="_5-6-nn与2nn" tabindex="-1"><a class="header-anchor" href="#_5-6-nn与2nn" aria-hidden="true">#</a> 5.6 NN与2NN</h2><h3 id="_5-6-1-hdfs-元数据管理机制" tabindex="-1"><a class="header-anchor" href="#_5-6-1-hdfs-元数据管理机制" aria-hidden="true">#</a> 5.6.1 HDFS 元数据管理机制</h3><p><strong>问题1:</strong> NameNode如何管理和存储元数据?</p><blockquote><p>计算机中存储数据两种: 内存或者是磁盘。</p></blockquote><ul><li><p>元数据存储磁盘: 存储磁盘无法面对客户端对元数据信息的任意的快速低延迟的响应，但是安全性高。</p></li><li><p>元数据存储内存: 元数据存放内存，可以高效的查询以及快速响应客户端的查询请求。数据保存在内存，如果断电，内存中的数据全部丢失。</p></li></ul><p>解决方案: 内存+磁盘; 更具体讲就是 NameNode内存 + FsImage的文件(磁盘)</p><p><strong>新问题:</strong> 磁盘和内存中元数据如何划分?</p><p>两个数据一模一样，还是两个数据合并到一起才是一份完整的数据呢?</p><ul><li>一模一样: client如果对元数据进行增删改操作，需要保证两个数据的一致性。而且 fsImage 文件操作起来效率也不高。</li><li>合并产生完整数据: 为了解决 fsImage 文件操作效率不高的问题，NameNode 引入了一个 edits 文件(简单理解为日志文件,特点是只能追加写入)， edits 文件记录的是 client 的增删改操作，不再选择让 NameNode 把数据 dump 出来形成 FsImage 文件(这种操作是比较消耗资源)。</li></ul><p>元数据管理流程图</p><p><img src="/doc/assets/README-1639967734215.46be8544.png" alt="元数据管理流程图"></p><blockquote><p>镜像文件可以理解为从内存中 Dump 出来的一份数据</p></blockquote><h4 id="第一阶段-namenode启动" tabindex="-1"><a class="header-anchor" href="#第一阶段-namenode启动" aria-hidden="true">#</a> 第一阶段: NameNode启动</h4><ol><li>第一次启动 NameNode 格式化后，创建 Fsimage 和 Edits 文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</li><li>客户端对元数据进行增删改的请求。</li><li>NameNode记录操作日志，更新滚动日志。</li><li>NameNode在内存中对数据进行增删改。</li></ol><blockquote><p>例如客户端向 NameNode 请求往根目录添加一文件，首先会把这个添加操作的元数据(文件大小、块等信息)记录到 edits 文件中，再把记录的操作向内存发送。内存会更新元数据信息。</p><p>假设此时宕机，内存中数据丢失了，但是 edits 文件中仍然有数据。系统重启会重新加载 edits 文件和 fsImage 文件的信息，数据又恢复了。</p></blockquote><h4 id="第二阶段-secondary-namenode-工作" tabindex="-1"><a class="header-anchor" href="#第二阶段-secondary-namenode-工作" aria-hidden="true">#</a> 第二阶段: Secondary NameNode 工作</h4><ol><li>Secondary NameNode 询问 NameNode 是否需要CheckPoint。直接带回 NameNode 是否执行检查点操作结果。</li><li>Secondary NameNode 请求执行 CheckPoint。</li><li>NameNode滚动正在写的Edits日志。</li><li>将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。</li><li>Secondary NameNode 加载编辑日志(NameNode滚动好的日志文件)和镜像文件(NameNode的fsimage)到内存，并合并。</li><li>生成新的镜像文件 <code>fsimage.chkpoint</code>。</li><li>拷贝 <code>fsimage.chkpoint</code> 到NameNode。</li><li>NameNode 将 <code>fsimage.chkpoint</code> 重新命名成 <code>fsimage</code>。</li></ol><blockquote><p>也就是将 edits 文件与 fsimage 文件加载到内存合并，并从内存中 dump 出文件的操作交给 SecondaryNameNode 节点</p></blockquote><h3 id="_5-6-2-fsimage-与-edits-文件解析" tabindex="-1"><a class="header-anchor" href="#_5-6-2-fsimage-与-edits-文件解析" aria-hidden="true">#</a> 5.6.2 fsimage 与 edits 文件解析</h3><p>NameNode 在执行格式化之后，会在 <code>/opt/zmn/servers/hadoop-2.9.2/data/tmp/dfs/name/current</code> 目录下产生如下文件</p><div class="language-text ext-text line-numbers-mode"><pre class="language-text"><code>-rw-r--r--. 1 root root     977 Dec 19 22:17 edits_0000000000000000322-0000000000000000335
-rw-r--r--. 1 root root     852 Dec 20 20:38 edits_0000000000000000336-0000000000000000349 // 记录了客户端对 HDFS 集群进行元数据更新的操作
-rw-r--r--. 1 root root 1048576 Dec 20 20:38 edits_inprogress_0000000000000000350
-rw-r--r--. 1 root root    3379 Dec 19 22:17 fsimage_0000000000000000335     // name node 内存数据的镜像 
-rw-r--r--. 1 root root      62 Dec 19 22:17 fsimage_0000000000000000335.md5 // 与 secondary name node 进行数据传输的校验文件 
-rw-r--r--. 1 root root    3381 Dec 20 20:38 fsimage_0000000000000000349
-rw-r--r--. 1 root root      62 Dec 20 20:38 fsimage_0000000000000000349.md5
-rw-r--r--. 1 root root       4 Dec 20 20:38 seen_txid 
-rw-r--r--. 1 root root     218 Dec 18 18:17 VERSION
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><ul><li>fsimage 文件: 是 NameNode 中关于元数据的镜像，一般称为检查点，这里包含了HDFS文件系统所有目录以及文件相关信息(Block数量，副本数量，权限等信息)</li><li>edits文件: 存储了客户端对HDFS文件系统所有的更新操作记录，Client 对HDFS文件系统所有的更新操作都会被记录到 edits 文件中(不包括查询操作)</li><li>seen_txid: 该文件是保存了一个数字，数字对应着最后一个 edits 文件名的数字</li><li>VERSION: 该文件记录 NameNode 的一些版本号信息，比如: CusterId, namespaceID等</li></ul><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token function">cat</span> seen_txid 
<span class="token number">350</span>

<span class="token function">cat</span> VERSION 
<span class="token comment">#Sat Dec 18 18:17:43 CST 2021</span>
<span class="token assign-left variable">namespaceID</span><span class="token operator">=</span><span class="token number">766851790</span> <span class="token comment"># 命名空间ID</span>
<span class="token assign-left variable">clusterID</span><span class="token operator">=</span>CID-0898fe10-2b09-4b06-b403-4fa3b5869f03 <span class="token comment"># 当前集群的唯一标志</span>
<span class="token assign-left variable">cTime</span><span class="token operator">=</span><span class="token number">1639822663933</span>
<span class="token assign-left variable">storageType</span><span class="token operator">=</span>NAME_NODE
<span class="token assign-left variable">blockpoolID</span><span class="token operator">=</span>BP-628321235-192.168.179.121-1639822663933 <span class="token comment"># 块池ID</span>
<span class="token assign-left variable">layoutVersion</span><span class="token operator">=</span>-63
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h4 id="_5-6-2-1-fsimage-文件内容" tabindex="-1"><a class="header-anchor" href="#_5-6-2-1-fsimage-文件内容" aria-hidden="true">#</a> 5.6.2.1 fsimage 文件内容</h4><blockquote><p>官方帮助文档：<a href="https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html" target="_blank" rel="noopener noreferrer">https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>fsimage 是二进制文件，不能直接查看，不过可以通过官方工具oiv和oev命令</p><ul><li>oiv: Offline Image Viewer View a Hadoop fsimage INPUTFILE using the specified PROCESSOR,saving the results in OUTPUTFILE.</li><li>oev: Offline edits viewer Parse a Hadoop edits log file INPUT_FILE and save results in OUTPUT_FILE</li></ul><p>基本语法: <code>hdfs oiv -p 文件类型(xml) -i 镜像文件 -o 转换后文件输出路径</code></p><p>测试案例</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 生成可视化文件</span>
hdfs oiv -p XML -i fsimage_0000000000000000349 -o /root/image349.xml
<span class="token comment"># 查看</span>
<span class="token function">cat</span> /root/image349.xml
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>问题: fsimage 中为什么没有记录块所在的 DataNode?</p><p>在内存元数据中是有记录块所在 DataNode 信息的，但是 fsimage 中剔除了这个信息;</p><p>HDFS集群在启动的时候会加载 image 以及 edits 文件，Block所在的 DataNode 信息在这两个文件中都没有记录。</p><p>集群启动时会有一个安全模式 (SafeMode), 安全模式就是为了让 DataNode 汇报自己当前所持有的 Block 信息给 NameNode 来补全元数据。后续每隔一段时间 DataNode 都要汇报自己持有的 Block 信息。</p><h4 id="_5-6-2-2-edits文件内容" tabindex="-1"><a class="header-anchor" href="#_5-6-2-2-edits文件内容" aria-hidden="true">#</a> 5.6.2.2 edits文件内容</h4><p>基本语法</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>测试案例</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 生成</span>
hdfs oev -p XML -i edits_0000000000000000336-0000000000000000349 -o /root/edits_351.xml
<span class="token comment"># 查看</span>
<span class="token function">cat</span> /root/edits_351.xml 
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><blockquote><p>备注: edits 中只记录了更新相关的操作，查询或者下载文件并不会记录在内!!</p></blockquote><p>问题: NameNode 启动时如何确定加载哪些 edits 文件呢?</p><p>NameNode 启动时需要加载 fsimage 文件以及那些没有被 SecondaryNameNode 进行合并的edits文件。</p><p>问题二：NameNode 如何判断哪些 edits 已经被合并了呢?</p><p>可以通过 fsimage 文件自身的编号来确定哪些已经被合并。</p><blockquote><p>fsimage 文件的编号等于已经合并的 edits 文件的编号。</p></blockquote><h3 id="_5-6-3-checkpoint-周期" tabindex="-1"><a class="header-anchor" href="#_5-6-3-checkpoint-周期" aria-hidden="true">#</a> 5.6.3 checkpoint 周期</h3><p>配置文件 <code>hdfs-default.xml</code> 默认信息如下：</p><div class="language-xml ext-xml line-numbers-mode"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 定时：一小时 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.checkpoint.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>3600<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">&gt;</span></span>The number of seconds between two periodic checkpoints.
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token comment">&lt;!-- 一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.checkpoint.txns<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>1000000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">&gt;</span></span>The Secondary NameNode or CheckpointNode will create a checkpoint
            of the namespace every &#39;dfs.namenode.checkpoint.txns&#39; transactions, regardless
            of whether &#39;dfs.namenode.checkpoint.period&#39; has expired.
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.checkpoint.check.period<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>60<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">&gt;</span></span>The SecondaryNameNode and CheckpointNode will poll the NameNode
            every &#39;dfs.namenode.checkpoint.check.period&#39; seconds to query the number
            of uncheckpointed transactions.
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h2 id="_5-7-nn故障处理" tabindex="-1"><a class="header-anchor" href="#_5-7-nn故障处理" aria-hidden="true">#</a> 5.7 NN故障处理</h2><p>NameNode 故障后，HDFS 集群就无法正常工作，因为 HDFS 文件系统的元数据需要由 NameNode 来管理维护并与 Client 交互， 如果元数据出现损坏和丢失同样会导致 NameNode 无法正常工作进而 HDFS 文件系统无法正常对外提供服务。</p><p>如果元数据出现丢失损坏如何恢复呢?</p><ol><li>将2NN的元数据拷贝到NN的节点下</li></ol><blockquote><p>此种方式会存在元数据的丢失。会丢失两次 checkpoint 之间产生的新的元数据。</p></blockquote><ol start="2"><li>搭建HDFS的HA(高可用)集群，解决NN的单点故障问题!!!</li></ol><blockquote><p>借助 Zookeeper 实现HA，一个 Active 的 NameNode,一个 Standby 的 NameNode。</p></blockquote><h2 id="_5-8-限额与归档及集群安全模式" tabindex="-1"><a class="header-anchor" href="#_5-8-限额与归档及集群安全模式" aria-hidden="true">#</a> 5.8 限额与归档及集群安全模式</h2><h3 id="_5-8-1-hdfs文件限额配置" tabindex="-1"><a class="header-anchor" href="#_5-8-1-hdfs文件限额配置" aria-hidden="true">#</a> 5.8.1 HDFS文件限额配置</h3><p>HDFS文件的限额配置允许我们以文件大小或者文件个数来限制我们在某个目录下上传的文件数量或者文件内容总量， 以便达到我们类似百度网盘等限制每个用户允许上传的最大的文件的量。</p><ol><li>数量限额</li></ol><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 创建hdfs文件夹</span>
hdfs dfs -mkdir -p /user/root/zmn
<span class="token comment"># 给该文件夹下面设置最多上传两个文件，上传文件，发现只能上传一个文件</span>
hdfs dfsadmin -setQuota <span class="token number">2</span> /user/root/zmn 

<span class="token comment"># put: The NameSpace quota (directories and files) of directory /user/root/zmn is exceeded: quota=2 file count=3</span>

<span class="token comment"># 清除文件数量限制</span>
hdfs dfsadmin -clrQuota /user/root/zmn
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><ol start="2"><li>空间大小限额</li></ol><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 限制空间大小4KB</span>
hdfs dfsadmin -setSpaceQuota 4k /user/root/zmn  
<span class="token comment"># 上传超过4Kb的文件大小上去提示文件超过限额</span>
hdfs dfs -put -put /opt/zmn/software/jdk-8u231-linux-x64.tar.gz /user/root/zmn
<span class="token comment"># put: The DiskSpace quota of /user/root/zmn is exceeded: quota = 4096 B = 4 KB but diskspace consumed = 402653184 B = 384 MB</span>
<span class="token comment"># 清除空间限额</span>
hdfs dfsadmin -clrSpaceQuota /user/root/zmn 
<span class="token comment">#查看hdfs文件限额数量</span>
hdfs dfs -count -q -h /user/root/zmn
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h3 id="_5-8-2-hdfs的安全模式" tabindex="-1"><a class="header-anchor" href="#_5-8-2-hdfs的安全模式" aria-hidden="true">#</a> 5.8.2 HDFS的安全模式</h3><blockquote><p>HDFS 集群启动时需要加载 fsimage 以及 edit 文件，而这两个文件都没有记录 Block 所在的 DataNode 节点信息，如果此时 Client 请求下载文件，集群是不能工作的。</p></blockquote><p>安全模式是 HDFS 所处的一种特殊状态，在这种状态下，文件系统只接受读数据请求，而不接受删除、修改等变更请求。</p><p>在 NameNode 主节点启动时，HDFS 首先进入安全模式，DataNode 在启动的时候会向 NameNode 汇报可用的 block 等状态， 当整个系统达到安全标准时，HDFS 自动离开安全模式。</p><p>如果 HDFS 处于安全模式下，则文件 block 不能进行任何的副本复制操作，因此达到最小的副本数量要求是基于 DataNode 启动时的状态来判定的， 启动时不会再做任何复制(从而达到最小副本数量要求)。</p><p>HDFS 集群刚启动的时候，默认30S钟的时间是处于安全期的，只有过了 30S 之后，集群脱离了安全期，然后才可以对集群进行操作。</p><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code><span class="token comment"># 进入或退出安全模式</span>
hdfs dfsadmin -safemode <span class="token operator">&lt;</span>enter<span class="token operator">|</span>leave<span class="token operator">|</span>get<span class="token operator">|</span><span class="token function">wait</span><span class="token operator">|</span>forceExit<span class="token operator">&gt;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="_5-8-3-hadoop归档技术" tabindex="-1"><a class="header-anchor" href="#_5-8-3-hadoop归档技术" aria-hidden="true">#</a> 5.8.3 Hadoop归档技术</h3><blockquote><p>主要解决HDFS集群存在大量小文件的问题!!</p></blockquote><p>由于大量小文件会占用 NameNode 的内存，因此对 HDFS 来说存储大量小文件会造成 NameNode 内存资源的浪费!</p><p>Hadoop 存档文件 HAR 文件，是一个更高效的文件存档工具，HAR 文件是由一组文件通过 archive 工具创建而来， 在减少了 NameNode 的内存使用的同时，可以对文件进行透明的访问，通俗来说就是 HAR 文件对 NameNode 来说是一个文件减少了内存的浪费， 对于实际操作处理文件依然是一个一个独立的文件。</p><blockquote><p>归档成一个文件，NameNode 认为是一个整体，但是内部仍然是多个小文件。</p></blockquote><h4 id="测试案例" tabindex="-1"><a class="header-anchor" href="#测试案例" aria-hidden="true">#</a> 测试案例</h4><ol><li>启动 YARN 集群</li></ol><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>start-yarn.sh
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><ol start="2"><li>归档文件</li></ol><p>把 <code>/wcinput</code> 目录里面的所有文件归档成一个叫 <code>input.har</code> 的归档文件，并把归档后文件存储到 <code>/root/output</code> 路径下。</p><blockquote><p>这里的这些文件夹都是 HDFS 服务里面的文件夹。</p></blockquote><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>hadoop archive -archiveName input.har -p /wcinput /root/output
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><p><img src="/doc/assets/README-1640095506179.41114f62.png" alt="归档文件查看"></p><ol start="3"><li>查看归档</li></ol><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>hdfs dfs -ls -R /root/output/input.har
-rw-r--r--   <span class="token number">3</span> root supergroup          <span class="token number">0</span> <span class="token number">2021</span>-12-21 <span class="token number">22</span>:02 /root/output/input.har/_SUCCESS
-rw-r--r--   <span class="token number">3</span> root supergroup        <span class="token number">190</span> <span class="token number">2021</span>-12-21 <span class="token number">22</span>:02 /root/output/input.har/_index
-rw-r--r--   <span class="token number">3</span> root supergroup         <span class="token number">22</span> <span class="token number">2021</span>-12-21 <span class="token number">22</span>:02 /root/output/input.har/_masterindex
-rw-r--r--   <span class="token number">3</span> root supergroup         <span class="token number">99</span> <span class="token number">2021</span>-12-21 <span class="token number">22</span>:02 /root/output/input.har/part-0

<span class="token comment"># 这种查看方式可以查看原始的数据文件</span>
hdfs dfs -ls -R har:///root/output/input.har
-rw-r--r--   <span class="token number">3</span> root supergroup         <span class="token number">71</span> <span class="token number">2021</span>-12-18 <span class="token number">19</span>:38 har:///root/output/input.har/wc.txt
-rw-r--r--   <span class="token number">3</span> root supergroup         <span class="token number">28</span> <span class="token number">2021</span>-12-21 <span class="token number">22</span>:01 har:///root/output/input.har/yarn.txt
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><ol start="4"><li>解归档文件</li></ol><div class="language-bash ext-sh line-numbers-mode"><pre class="language-bash"><code>hdfs dfs -cp har:///root/output/input.har/* /wcoutput
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br></div></div><h2 id="_5-9-日志采集综合案例" tabindex="-1"><a class="header-anchor" href="#_5-9-日志采集综合案例" aria-hidden="true">#</a> 5.9 日志采集综合案例</h2><h3 id="_5-9-1-需求分析" tabindex="-1"><a class="header-anchor" href="#_5-9-1-需求分析" aria-hidden="true">#</a> 5.9.1 需求分析</h3><ul><li>定时采集已滚动完毕日志文件</li><li>将待采集文件上传到临时目录</li><li>备份日志文件</li></ul><h3 id="_5-9-2-代码实现" tabindex="-1"><a class="header-anchor" href="#_5-9-2-代码实现" aria-hidden="true">#</a> 5.9.2 代码实现</h3><blockquote><p>所需依赖与前面的实例项目一致，此处不在赘述。</p></blockquote><ol><li>创建日志搜集主类</li></ol><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogCollector</span> <span class="token punctuation">{</span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token class-name">Timer</span> timer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Timer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 定时采集任务的调度</span>
        <span class="token comment">// task: 采集的业务逻辑；延迟时间；周期时间</span>
        timer<span class="token punctuation">.</span><span class="token function">schedule</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">LogCollectorTask</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3600</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><ol start="2"><li>收集日志主要业务逻辑实现</li></ol><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogCollectorTask</span> <span class="token keyword">extends</span> <span class="token class-name">TimerTask</span> <span class="token punctuation">{</span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 采集的业务逻辑</span>
        <span class="token class-name">SimpleDateFormat</span> sdf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SimpleDateFormat</span><span class="token punctuation">(</span><span class="token string">&quot;yyyy-MM-dd&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> todayStr <span class="token operator">=</span> sdf<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 1.扫描指定目录，找到待上传文件</span>
        <span class="token class-name">File</span> logsDir <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">&quot;/opt/a/logs&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">File</span><span class="token punctuation">[</span><span class="token punctuation">]</span> uploadFiles <span class="token operator">=</span> logsDir<span class="token punctuation">.</span><span class="token function">listFiles</span><span class="token punctuation">(</span><span class="token punctuation">(</span>dir<span class="token punctuation">,</span> name<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> name<span class="token punctuation">.</span><span class="token function">startsWith</span><span class="token punctuation">(</span><span class="token string">&quot;access.log.&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 2.把待上传文件转移到临时目录</span>
        <span class="token comment">// 2.1.判断是否存在临时目录</span>
        <span class="token class-name">File</span> tmpDir <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">&quot;/opt/a/log_tmp/&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>tmpDir<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            tmpDir<span class="token punctuation">.</span><span class="token function">mkdirs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">File</span> file <span class="token operator">:</span> uploadFiles<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            file<span class="token punctuation">.</span><span class="token function">renameTo</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>tmpDir<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;/&quot;</span> <span class="token operator">+</span> file<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>

        <span class="token comment">// 3.使用 HDFS API 上传文件到指定目录</span>
        <span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        conf<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">&quot;fs.defaultFS&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;hdfs://linux121:9000&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">FileSystem</span> fs <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            fs <span class="token operator">=</span> <span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 判断 HDFS 目标路径是否存在,备份目录是否存在</span>
            <span class="token class-name">Path</span> path <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/collect_log/&quot;</span> <span class="token operator">+</span> todayStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>fs<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                fs<span class="token punctuation">.</span><span class="token function">mkdirs</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>

            <span class="token class-name">File</span> bakDir <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">&quot;/opt/a/log_bak/&quot;</span> <span class="token operator">+</span> todayStr<span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>bakDir<span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                bakDir<span class="token punctuation">.</span><span class="token function">mkdirs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
            <span class="token class-name">File</span><span class="token punctuation">[</span><span class="token punctuation">]</span> files <span class="token operator">=</span> tmpDir<span class="token punctuation">.</span><span class="token function">listFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">File</span> file <span class="token operator">:</span> files<span class="token punctuation">)</span> <span class="token punctuation">{</span>
                <span class="token comment">// 按照日期分门别类存放</span>
                fs<span class="token punctuation">.</span><span class="token function">copyFromLocalFile</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>file<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span><span class="token string">&quot;/collect_log/&quot;</span> <span class="token operator">+</span> file<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token comment">// 4.上传后的文件转移到备份目录</span>
                file<span class="token punctuation">.</span><span class="token function">renameTo</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span>bakDir<span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">&quot;/&quot;</span> <span class="token operator">+</span> file<span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br></div></div><h3 id="_5-9-3-代码优化" tabindex="-1"><a class="header-anchor" href="#_5-9-3-代码优化" aria-hidden="true">#</a> 5.9.3 代码优化</h3><ul><li>配置文件</li></ul><p>目录等信息，不硬编码在代码中，使用配置文件。</p><ul><li>常量类</li></ul><p><code>Properties</code> 的 Key 使用常量定义。</p><ul><li>单例模式</li></ul><p>加载配置文件，使用单例的工具类加载。</p><div class="language-java ext-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">PropTool</span> <span class="token punctuation">{</span>

    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>

    <span class="token comment">// 静态代码块初始化</span>
    <span class="token keyword">static</span> <span class="token punctuation">{</span>
        properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">try</span> <span class="token punctuation">{</span>
            properties<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token class-name">LogCollectorTask</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getClassLoader</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getResourceAsStream</span><span class="token punctuation">(</span><span class="token string">&quot;collector.properties&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">IOException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
            e<span class="token punctuation">.</span><span class="token function">printStackTrace</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">Properties</span> <span class="token function">getProperties</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">return</span> properties<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token keyword">private</span> <span class="token class-name">PropTool</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token punctuation">}</span>

<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><!--]--></div><footer class="page-meta"><div class="meta-item edit-link"><a class="external-link meta-item-label" href="https://github.com/faustine8/doc/edit/main/docs/bigdata/hadoop/core/hdfs/README.md" rel="noopener noreferrer" target="_blank" aria-label="在 GitHub 上编辑"><!--[--><!--]--> 在 GitHub 上编辑 <span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!--[--><!--]--></a></div><div class="meta-item last-updated"><span class="meta-item-label">更新时间: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">贡献者: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: faustine923@icloud.com">mujunlin</span><!----><!--]--><!--]--></span></div></footer><!----><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/doc/assets/app.40df414d.js" defer></script>
  </body>
</html>
